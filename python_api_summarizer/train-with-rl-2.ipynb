{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7ff30f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-12T07:34:53.662397Z",
     "iopub.status.busy": "2025-05-12T07:34:53.662073Z",
     "iopub.status.idle": "2025-05-12T07:34:53.666505Z",
     "shell.execute_reply": "2025-05-12T07:34:53.665916Z"
    },
    "papermill": {
     "duration": 0.010072,
     "end_time": "2025-05-12T07:34:53.667729",
     "exception": false,
     "start_time": "2025-05-12T07:34:53.657657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_docs_addr = '/kaggle/input/indian-doc-summary-dataset/IN-Abs/train-data/judgement'\n",
    "train_sums_addr = '/kaggle/input/indian-doc-summary-dataset/IN-Abs/train-data/summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c3ba670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T07:34:53.675313Z",
     "iopub.status.busy": "2025-05-12T07:34:53.675074Z",
     "iopub.status.idle": "2025-05-12T07:34:53.677787Z",
     "shell.execute_reply": "2025-05-12T07:34:53.677198Z"
    },
    "papermill": {
     "duration": 0.007586,
     "end_time": "2025-05-12T07:34:53.678862",
     "exception": false,
     "start_time": "2025-05-12T07:34:53.671276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cdaeab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T07:34:53.685393Z",
     "iopub.status.busy": "2025-05-12T07:34:53.685174Z",
     "iopub.status.idle": "2025-05-12T07:35:39.507067Z",
     "shell.execute_reply": "2025-05-12T07:35:39.506317Z"
    },
    "papermill": {
     "duration": 45.826988,
     "end_time": "2025-05-12T07:35:39.508831",
     "exception": false,
     "start_time": "2025-05-12T07:34:53.681843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "train_df = pd.DataFrame()\n",
    "\n",
    "train_docs = []\n",
    "train_sums = []\n",
    "doc_num = []\n",
    "\n",
    "for doc in os.listdir(train_docs_addr):\n",
    "    with open(train_docs_addr + '/' + doc, \"r\") as file:\n",
    "        train_docs.append(file.read())\n",
    "        doc_num.append(doc)\n",
    "\n",
    "for summ in os.listdir(train_sums_addr):\n",
    "    with open(train_sums_addr + '/' + summ, \"r\") as file:\n",
    "        train_sums.append(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da464c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T07:35:39.516495Z",
     "iopub.status.busy": "2025-05-12T07:35:39.516101Z",
     "iopub.status.idle": "2025-05-12T07:35:39.548130Z",
     "shell.execute_reply": "2025-05-12T07:35:39.547392Z"
    },
    "papermill": {
     "duration": 0.037168,
     "end_time": "2025-05-12T07:35:39.549536",
     "exception": false,
     "start_time": "2025-05-12T07:35:39.512368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1893.txt</td>\n",
       "      <td>iminal Appeal No. 47 of 1963.\\nAppeal by speci...</td>\n",
       "      <td>The appellant published in his paper, which ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1711.txt</td>\n",
       "      <td>minal Appeal No. 210 of 1963.\\nAppeal by speci...</td>\n",
       "      <td>On the first information report lodged by the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4682.txt</td>\n",
       "      <td>Civil Appeal No. 2618 of 1983.\\nFrom the Judgm...</td>\n",
       "      <td>The first respondent who lost to the appellant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5450.txt</td>\n",
       "      <td>ivil Appeal No. 2991 of 1986.\\nFrom the Judgme...</td>\n",
       "      <td>The appellant was sought to be evicted under s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5064.txt</td>\n",
       "      <td>Civil Appeal No. 1733 of 1973.\\nFrom the Judgm...</td>\n",
       "      <td>A firm (JTC) obtained the sole selling agency ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Doc                                               Text  \\\n",
       "0  1893.txt  iminal Appeal No. 47 of 1963.\\nAppeal by speci...   \n",
       "1  1711.txt  minal Appeal No. 210 of 1963.\\nAppeal by speci...   \n",
       "2  4682.txt  Civil Appeal No. 2618 of 1983.\\nFrom the Judgm...   \n",
       "3  5450.txt  ivil Appeal No. 2991 of 1986.\\nFrom the Judgme...   \n",
       "4  5064.txt  Civil Appeal No. 1733 of 1973.\\nFrom the Judgm...   \n",
       "\n",
       "                                             Summary  \n",
       "0  The appellant published in his paper, which ha...  \n",
       "1  On the first information report lodged by the ...  \n",
       "2  The first respondent who lost to the appellant...  \n",
       "3  The appellant was sought to be evicted under s...  \n",
       "4  A firm (JTC) obtained the sole selling agency ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Doc'] = doc_num\n",
    "train_df['Text'] = train_docs\n",
    "train_df['Summary'] = train_sums\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a352df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T07:35:39.556778Z",
     "iopub.status.busy": "2025-05-12T07:35:39.556548Z",
     "iopub.status.idle": "2025-05-12T07:35:39.572618Z",
     "shell.execute_reply": "2025-05-12T07:35:39.572044Z"
    },
    "papermill": {
     "duration": 0.021032,
     "end_time": "2025-05-12T07:35:39.573804",
     "exception": false,
     "start_time": "2025-05-12T07:35:39.552772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Open the file and read lines\n",
    "with open(\"/kaggle/input/indian-doc-summary-dataset/IN-Abs/train-data/stats-IN-train.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Extract the second column values\n",
    "second_column_values = [int(line.split()[1]) for line in lines]\n",
    "\n",
    "# Extract the second column values\n",
    "third_column_values = [int(line.split()[2]) for line in lines]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f40fc4db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T07:35:39.580731Z",
     "iopub.status.busy": "2025-05-12T07:35:39.580528Z",
     "iopub.status.idle": "2025-05-12T07:35:39.587828Z",
     "shell.execute_reply": "2025-05-12T07:35:39.587278Z"
    },
    "papermill": {
     "duration": 0.012109,
     "end_time": "2025-05-12T07:35:39.589044",
     "exception": false,
     "start_time": "2025-05-12T07:35:39.576935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics as stats\n",
    "def list_metrics(lst):\n",
    "    metrics = {\n",
    "        \"min\": min(lst),\n",
    "        \"max\": max(lst),\n",
    "        \"mean\": np.mean(lst),\n",
    "        \"median\": np.median(lst),\n",
    "        \"mode\": stats.mode(lst),\n",
    "        \"std_dev\": np.std(lst),\n",
    "        \"variance\": np.var(lst),\n",
    "        \"sum\": sum(lst),\n",
    "        \"count\": len(lst),\n",
    "        \"range\": max(lst) - min(lst),\n",
    "        \"25th_percentile\": np.percentile(lst, 25),\n",
    "        \"75th_percentile\": np.percentile(lst, 75),\n",
    "        \"iqr\": np.percentile(lst, 75) - np.percentile(lst, 25),\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5415951a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T07:35:39.595890Z",
     "iopub.status.busy": "2025-05-12T07:35:39.595697Z",
     "iopub.status.idle": "2025-05-12T07:35:39.606931Z",
     "shell.execute_reply": "2025-05-12T07:35:39.606279Z"
    },
    "papermill": {
     "duration": 0.015896,
     "end_time": "2025-05-12T07:35:39.608038",
     "exception": false,
     "start_time": "2025-05-12T07:35:39.592142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 94,\n",
       " 'max': 139867,\n",
       " 'mean': 4371.1587482219065,\n",
       " 'median': 3131.0,\n",
       " 'mode': 2424,\n",
       " 'std_dev': 5116.888605821558,\n",
       " 'variance': 26182549.004386485,\n",
       " 'sum': 30729246,\n",
       " 'count': 7030,\n",
       " 'range': 139773,\n",
       " '25th_percentile': 2019.0,\n",
       " '75th_percentile': 4974.75,\n",
       " 'iqr': 2955.75}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_metrics(second_column_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4445bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T07:35:39.615048Z",
     "iopub.status.busy": "2025-05-12T07:35:39.614856Z",
     "iopub.status.idle": "2025-05-12T07:35:39.624504Z",
     "shell.execute_reply": "2025-05-12T07:35:39.623852Z"
    },
    "papermill": {
     "duration": 0.014506,
     "end_time": "2025-05-12T07:35:39.625827",
     "exception": false,
     "start_time": "2025-05-12T07:35:39.611321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 0,\n",
       " 'max': 27795,\n",
       " 'mean': 841.2209103840682,\n",
       " 'median': 640.0,\n",
       " 'mode': 503,\n",
       " 'std_dev': 900.0992865991495,\n",
       " 'variance': 810178.7257362979,\n",
       " 'sum': 5913783,\n",
       " 'count': 7030,\n",
       " 'range': 27795,\n",
       " '25th_percentile': 422.0,\n",
       " '75th_percentile': 965.0,\n",
       " 'iqr': 543.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_metrics(third_column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7733265e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T07:35:39.633465Z",
     "iopub.status.busy": "2025-05-12T07:35:39.633206Z",
     "iopub.status.idle": "2025-05-12T07:35:39.636377Z",
     "shell.execute_reply": "2025-05-12T07:35:39.635734Z"
    },
    "papermill": {
     "duration": 0.008155,
     "end_time": "2025-05-12T07:35:39.637539",
     "exception": false,
     "start_time": "2025-05-12T07:35:39.629384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df = train_df.sample(n=500, random_state=42).reset_index(drop=True)\n",
    "train_df = train_df[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03bc6d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T07:35:39.644633Z",
     "iopub.status.busy": "2025-05-12T07:35:39.644439Z",
     "iopub.status.idle": "2025-05-12T07:35:39.655676Z",
     "shell.execute_reply": "2025-05-12T07:35:39.654898Z"
    },
    "papermill": {
     "duration": 0.016141,
     "end_time": "2025-05-12T07:35:39.656883",
     "exception": false,
     "start_time": "2025-05-12T07:35:39.640742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1893.txt</td>\n",
       "      <td>iminal Appeal No. 47 of 1963.\\nAppeal by speci...</td>\n",
       "      <td>The appellant published in his paper, which ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1711.txt</td>\n",
       "      <td>minal Appeal No. 210 of 1963.\\nAppeal by speci...</td>\n",
       "      <td>On the first information report lodged by the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4682.txt</td>\n",
       "      <td>Civil Appeal No. 2618 of 1983.\\nFrom the Judgm...</td>\n",
       "      <td>The first respondent who lost to the appellant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5450.txt</td>\n",
       "      <td>ivil Appeal No. 2991 of 1986.\\nFrom the Judgme...</td>\n",
       "      <td>The appellant was sought to be evicted under s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5064.txt</td>\n",
       "      <td>Civil Appeal No. 1733 of 1973.\\nFrom the Judgm...</td>\n",
       "      <td>A firm (JTC) obtained the sole selling agency ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>Civil Appeal No. 8 of 1951.\\nAppeal from the j...</td>\n",
       "      <td>S and B were sons of two brothers respectively...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1591.txt</td>\n",
       "      <td>Appeals Nos. 652, 653 and 757 of 1962.\\nAppeal...</td>\n",
       "      <td>The history of the Nathdwara Temple in the Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>3929.txt</td>\n",
       "      <td>N: Criminal Appeal No. 144 of 1972.\\nAppeal by...</td>\n",
       "      <td>On a complaint by the Additional Registrar of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>426.txt</td>\n",
       "      <td>iminal Appeal No. 86 of 1954.\\nAppeal under Ar...</td>\n",
       "      <td>The High Court has no jurisdiction to grant ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>409.txt</td>\n",
       "      <td>on No. 271 of 1955.\\nUnder article 32 of the C...</td>\n",
       "      <td>The petitioners registered firm has its head o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Doc                                               Text  \\\n",
       "0    1893.txt  iminal Appeal No. 47 of 1963.\\nAppeal by speci...   \n",
       "1    1711.txt  minal Appeal No. 210 of 1963.\\nAppeal by speci...   \n",
       "2    4682.txt  Civil Appeal No. 2618 of 1983.\\nFrom the Judgm...   \n",
       "3    5450.txt  ivil Appeal No. 2991 of 1986.\\nFrom the Judgme...   \n",
       "4    5064.txt  Civil Appeal No. 1733 of 1973.\\nFrom the Judgm...   \n",
       "..        ...                                                ...   \n",
       "395     5.txt  Civil Appeal No. 8 of 1951.\\nAppeal from the j...   \n",
       "396  1591.txt  Appeals Nos. 652, 653 and 757 of 1962.\\nAppeal...   \n",
       "397  3929.txt  N: Criminal Appeal No. 144 of 1972.\\nAppeal by...   \n",
       "398   426.txt  iminal Appeal No. 86 of 1954.\\nAppeal under Ar...   \n",
       "399   409.txt  on No. 271 of 1955.\\nUnder article 32 of the C...   \n",
       "\n",
       "                                               Summary  \n",
       "0    The appellant published in his paper, which ha...  \n",
       "1    On the first information report lodged by the ...  \n",
       "2    The first respondent who lost to the appellant...  \n",
       "3    The appellant was sought to be evicted under s...  \n",
       "4    A firm (JTC) obtained the sole selling agency ...  \n",
       "..                                                 ...  \n",
       "395  S and B were sons of two brothers respectively...  \n",
       "396  The history of the Nathdwara Temple in the Dis...  \n",
       "397  On a complaint by the Additional Registrar of ...  \n",
       "398  The High Court has no jurisdiction to grant ce...  \n",
       "399  The petitioners registered firm has its head o...  \n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dce572a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T07:35:39.664326Z",
     "iopub.status.busy": "2025-05-12T07:35:39.664062Z",
     "iopub.status.idle": "2025-05-12T07:35:44.640674Z",
     "shell.execute_reply": "2025-05-12T07:35:44.639851Z"
    },
    "papermill": {
     "duration": 4.981761,
     "end_time": "2025-05-12T07:35:44.642093",
     "exception": false,
     "start_time": "2025-05-12T07:35:39.660332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install trl\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fc229b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T07:35:44.651306Z",
     "iopub.status.busy": "2025-05-12T07:35:44.651017Z",
     "iopub.status.idle": "2025-05-12T18:38:55.700601Z",
     "shell.execute_reply": "2025-05-12T18:38:55.699631Z"
    },
    "papermill": {
     "duration": 39791.107895,
     "end_time": "2025-05-12T18:38:55.754032",
     "exception": false,
     "start_time": "2025-05-12T07:35:44.646137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "==================================================\n",
      "STARTING SCRIPT\n",
      "==================================================\n",
      "Checking training data...\n",
      "train_df type: <class 'pandas.core.frame.DataFrame'>\n",
      "train_df shape: (400, 3)\n",
      "train_df columns: ['Doc', 'Text', 'Summary']\n",
      "\n",
      "==================================================\n",
      "STARTING LORA TRAINING PIPELINE\n",
      "==================================================\n",
      "Loading model and tokenizer with LoRA configuration...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd94bdae157d409886a3762e6950061a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896551e5666247eeb0398663235f6dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbe7c707bcc43f7aefe92ef8c1a0372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30820e966fb7427a93f348a00c853bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80e4cd9223d400cbf53f9124c12f7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,327,104 || all params: 163,171,584 || trainable%: 0.8133\n",
      "Model and tokenizer loaded successfully\n",
      "Preparing dataset with 400 examples\n",
      "Dataset columns: ['Doc', 'Text', 'Summary']\n",
      "Starting dataset tokenization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3c84b73ef74f7bb36999690516cc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparation complete. Feature names: ['input_ids', 'attention_mask', 'labels']\n",
      "Dataset size: 400\n",
      "Creating data collator...\n",
      "Creating DataLoader...\n",
      "Created DataLoader with 200 batches\n",
      "Initializing optimizer...\n",
      "Bitsandbytes not available, using standard AdamW\n",
      "\n",
      "==================================================\n",
      "STARTING TRAINING\n",
      "==================================================\n",
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194a1aa8ed8a44de85c3b58a2964937b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batch 1/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.8750\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8501\n",
      "Reward for example 1: 0.8951\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.5947\n",
      "Reward for example 2: 0.7163\n",
      "Average batch reward: 0.8057\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.7334\n",
      "\n",
      "Processing batch 2/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.7109\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9492\n",
      "Reward for example 1: 0.9645\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8701\n",
      "Reward for example 2: 0.9091\n",
      "Average batch reward: 0.9368\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.4131\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 3/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 8.5391\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8018\n",
      "Reward for example 1: 0.8612\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9600\n",
      "Reward for example 2: 0.9720\n",
      "Average batch reward: 0.9166\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 7.8269\n",
      "\n",
      "Processing batch 4/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.7656\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 934 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 934])\n",
      "Entailment score: 0.9082\n",
      "Reward for example 1: 0.9357\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 934])\n",
      "Entailment score: 0.7466\n",
      "Reward for example 2: 0.8226\n",
      "Average batch reward: 0.8792\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.0690\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 5/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 10.2500\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8291\n",
      "Reward for example 1: 0.8804\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8716\n",
      "Reward for example 2: 0.9101\n",
      "Average batch reward: 0.8952\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 9.1762\n",
      "\n",
      "Processing batch 6/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 6.9453\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 702 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 702])\n",
      "Entailment score: 0.6938\n",
      "Reward for example 1: 0.7857\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 702])\n",
      "Entailment score: 0.8662\n",
      "Reward for example 2: 0.9063\n",
      "Average batch reward: 0.8460\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.8759\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 7/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 7.3633\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7490\n",
      "Reward for example 1: 0.8243\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8911\n",
      "Reward for example 2: 0.9238\n",
      "Average batch reward: 0.8740\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 6.4359\n",
      "\n",
      "Processing batch 8/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 7.5117\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 749 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 749])\n",
      "Entailment score: 0.9019\n",
      "Reward for example 1: 0.9313\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 749])\n",
      "Entailment score: 0.8062\n",
      "Reward for example 2: 0.8643\n",
      "Average batch reward: 0.8978\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 6.7440\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 9/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 8.6641\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 687 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 687])\n",
      "Entailment score: 0.7773\n",
      "Reward for example 1: 0.8441\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 687])\n",
      "Entailment score: 0.7695\n",
      "Reward for example 2: 0.8387\n",
      "Average batch reward: 0.8414\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 7.2900\n",
      "\n",
      "Processing batch 10/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 6.5586\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 930 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 930])\n",
      "Entailment score: 0.7881\n",
      "Reward for example 1: 0.8517\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 930])\n",
      "Entailment score: 0.7437\n",
      "Reward for example 2: 0.8206\n",
      "Average batch reward: 0.8361\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.4837\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 11/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.6191\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9409\n",
      "Reward for example 1: 0.9586\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8535\n",
      "Reward for example 2: 0.8975\n",
      "Average batch reward: 0.9281\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.4307\n",
      "\n",
      "Processing batch 12/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 10.5625\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7603\n",
      "Reward for example 1: 0.8322\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9282\n",
      "Reward for example 2: 0.9498\n",
      "Average batch reward: 0.8910\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 9.4108\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 13/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 7.6523\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9004\n",
      "Reward for example 1: 0.9303\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9600\n",
      "Reward for example 2: 0.9720\n",
      "Average batch reward: 0.9511\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 7.2783\n",
      "\n",
      "Processing batch 14/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 11.3906\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7969\n",
      "Reward for example 1: 0.8578\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6709\n",
      "Reward for example 2: 0.7696\n",
      "Average batch reward: 0.8137\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 9.2688\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 15/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 6.3555\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9229\n",
      "Reward for example 1: 0.9460\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6025\n",
      "Reward for example 2: 0.7218\n",
      "Average batch reward: 0.8339\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.2997\n",
      "\n",
      "Processing batch 16/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.2617\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 754 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 754])\n",
      "Entailment score: 0.9111\n",
      "Reward for example 1: 0.9378\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 754])\n",
      "Entailment score: 0.8242\n",
      "Reward for example 2: 0.8770\n",
      "Average batch reward: 0.9074\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.7743\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 17/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 8.2109\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 933 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 933])\n",
      "Entailment score: 0.9644\n",
      "Reward for example 1: 0.9750\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 933])\n",
      "Entailment score: 0.8413\n",
      "Reward for example 2: 0.8889\n",
      "Average batch reward: 0.9320\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 7.6524\n",
      "\n",
      "Processing batch 18/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.8359\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9097\n",
      "Reward for example 1: 0.9368\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8999\n",
      "Reward for example 2: 0.9299\n",
      "Average batch reward: 0.9333\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.4470\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 19/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 7.5938\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9136\n",
      "Reward for example 1: 0.9395\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7456\n",
      "Reward for example 2: 0.8219\n",
      "Average batch reward: 0.8807\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 6.6879\n",
      "\n",
      "Processing batch 20/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 6.3633\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9565\n",
      "Reward for example 1: 0.9696\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7500\n",
      "Reward for example 2: 0.8250\n",
      "Average batch reward: 0.8973\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.7097\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 21/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 9.2344\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6719\n",
      "Reward for example 1: 0.7703\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8281\n",
      "Reward for example 2: 0.8797\n",
      "Average batch reward: 0.8250\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 7.6184\n",
      "\n",
      "Processing batch 22/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.0742\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8486\n",
      "Reward for example 1: 0.8940\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9180\n",
      "Reward for example 2: 0.9426\n",
      "Average batch reward: 0.9183\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.7414\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 23/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 7.0781\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7310\n",
      "Reward for example 1: 0.8117\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7017\n",
      "Reward for example 2: 0.7912\n",
      "Average batch reward: 0.8014\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.6725\n",
      "\n",
      "Processing batch 24/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.6523\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 981 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 981])\n",
      "Entailment score: 0.9253\n",
      "Reward for example 1: 0.9477\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 981])\n",
      "Entailment score: 0.8184\n",
      "Reward for example 2: 0.8729\n",
      "Average batch reward: 0.9103\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.2349\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 25/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 7.4297\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 630 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 630])\n",
      "Entailment score: 0.7437\n",
      "Reward for example 1: 0.8206\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 630])\n",
      "Entailment score: 0.7114\n",
      "Reward for example 2: 0.7980\n",
      "Average batch reward: 0.8093\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 6.0127\n",
      "\n",
      "Processing batch 26/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.5010\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9219\n",
      "Reward for example 1: 0.9453\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8857\n",
      "Reward for example 2: 0.9200\n",
      "Average batch reward: 0.9327\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.3999\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 27/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.9238\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 566 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 566])\n",
      "Entailment score: 0.8936\n",
      "Reward for example 1: 0.9255\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 566])\n",
      "Entailment score: 0.8643\n",
      "Reward for example 2: 0.9050\n",
      "Average batch reward: 0.9152\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.7608\n",
      "\n",
      "Processing batch 28/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.8438\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9307\n",
      "Reward for example 1: 0.9515\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6533\n",
      "Reward for example 2: 0.7573\n",
      "Average batch reward: 0.8544\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.2841\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 29/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 6.5430\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 825 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 825])\n",
      "Entailment score: 0.9082\n",
      "Reward for example 1: 0.9357\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 825])\n",
      "Entailment score: 0.7920\n",
      "Reward for example 2: 0.8544\n",
      "Average batch reward: 0.8951\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.8564\n",
      "\n",
      "Processing batch 30/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.1113\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8926\n",
      "Reward for example 1: 0.9248\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9517\n",
      "Reward for example 2: 0.9662\n",
      "Average batch reward: 0.9455\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.9962\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 31/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.3945\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9180\n",
      "Reward for example 1: 0.9426\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9326\n",
      "Reward for example 2: 0.9528\n",
      "Average batch reward: 0.9477\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.2170\n",
      "\n",
      "Processing batch 32/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.0547\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9404\n",
      "Reward for example 1: 0.9583\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6738\n",
      "Reward for example 2: 0.7717\n",
      "Average batch reward: 0.8650\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.3723\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 33/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 6.1523\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9346\n",
      "Reward for example 1: 0.9542\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8799\n",
      "Reward for example 2: 0.9159\n",
      "Average batch reward: 0.9351\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.7528\n",
      "\n",
      "Processing batch 34/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 7.6719\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7432\n",
      "Reward for example 1: 0.8202\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9258\n",
      "Reward for example 2: 0.9480\n",
      "Average batch reward: 0.8841\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 6.7829\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 35/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.2148\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9414\n",
      "Reward for example 1: 0.9590\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8789\n",
      "Reward for example 2: 0.9152\n",
      "Average batch reward: 0.9371\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.8869\n",
      "\n",
      "Processing batch 36/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.2705\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8701\n",
      "Reward for example 1: 0.9091\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8999\n",
      "Reward for example 2: 0.9299\n",
      "Average batch reward: 0.9195\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.1682\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 37/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 7.0312\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9111\n",
      "Reward for example 1: 0.9378\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7134\n",
      "Reward for example 2: 0.7994\n",
      "Average batch reward: 0.8686\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 6.1072\n",
      "\n",
      "Processing batch 38/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.3906\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7871\n",
      "Reward for example 1: 0.8510\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7266\n",
      "Reward for example 2: 0.8086\n",
      "Average batch reward: 0.8298\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.4731\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 39/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.4844\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9614\n",
      "Reward for example 1: 0.9730\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8770\n",
      "Reward for example 2: 0.9139\n",
      "Average batch reward: 0.9434\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.4004\n",
      "\n",
      "Processing batch 40/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.7695\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9336\n",
      "Reward for example 1: 0.9535\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8291\n",
      "Reward for example 2: 0.8804\n",
      "Average batch reward: 0.9169\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.2903\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 41/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.8672\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9258\n",
      "Reward for example 1: 0.9480\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7705\n",
      "Reward for example 2: 0.8394\n",
      "Average batch reward: 0.8937\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.3498\n",
      "\n",
      "Processing batch 42/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.7227\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7583\n",
      "Reward for example 1: 0.8308\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9326\n",
      "Reward for example 2: 0.9528\n",
      "Average batch reward: 0.8918\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.2118\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 43/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.8984\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 779 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 779])\n",
      "Entailment score: 0.8662\n",
      "Reward for example 1: 0.9063\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 779])\n",
      "Entailment score: 0.8633\n",
      "Reward for example 2: 0.9043\n",
      "Average batch reward: 0.9053\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.5293\n",
      "\n",
      "Processing batch 44/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 6.9023\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8857\n",
      "Reward for example 1: 0.9200\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7593\n",
      "Reward for example 2: 0.8315\n",
      "Average batch reward: 0.8758\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 6.0448\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 45/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.0781\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9434\n",
      "Reward for example 1: 0.9604\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9395\n",
      "Reward for example 2: 0.9576\n",
      "Average batch reward: 0.9590\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.0339\n",
      "\n",
      "Processing batch 46/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.8281\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9004\n",
      "Reward for example 1: 0.9303\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7383\n",
      "Reward for example 2: 0.8168\n",
      "Average batch reward: 0.8735\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.2175\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 47/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.0234\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8228\n",
      "Reward for example 1: 0.8759\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8779\n",
      "Reward for example 2: 0.9146\n",
      "Average batch reward: 0.8952\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.4972\n",
      "\n",
      "Processing batch 48/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 6.7227\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 1022 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1022])\n",
      "Entailment score: 0.8604\n",
      "Reward for example 1: 0.9022\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1022])\n",
      "Entailment score: 0.9102\n",
      "Reward for example 2: 0.9371\n",
      "Average batch reward: 0.9197\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 6.1827\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 49/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.5391\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8828\n",
      "Reward for example 1: 0.9180\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6899\n",
      "Reward for example 2: 0.7830\n",
      "Average batch reward: 0.8505\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.0098\n",
      "\n",
      "Processing batch 50/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.6250\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9067\n",
      "Reward for example 1: 0.9347\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9287\n",
      "Reward for example 2: 0.9501\n",
      "Average batch reward: 0.9424\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.4162\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 51/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.2266\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6802\n",
      "Reward for example 1: 0.7761\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7773\n",
      "Reward for example 2: 0.8441\n",
      "Average batch reward: 0.8101\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.2342\n",
      "\n",
      "Processing batch 52/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 8.2500\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 444 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 444])\n",
      "Entailment score: 0.6792\n",
      "Reward for example 1: 0.7754\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 444])\n",
      "Entailment score: 0.6880\n",
      "Reward for example 2: 0.7816\n",
      "Average batch reward: 0.7785\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 6.4228\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 53/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.4375\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8970\n",
      "Reward for example 1: 0.9279\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6992\n",
      "Reward for example 2: 0.7895\n",
      "Average batch reward: 0.8587\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.6690\n",
      "\n",
      "Processing batch 54/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.1719\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8735\n",
      "Reward for example 1: 0.9115\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8604\n",
      "Reward for example 2: 0.9022\n",
      "Average batch reward: 0.9069\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.8764\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 55/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.5547\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7563\n",
      "Reward for example 1: 0.8294\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7832\n",
      "Reward for example 2: 0.8482\n",
      "Average batch reward: 0.8388\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.1430\n",
      "\n",
      "Processing batch 56/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.8789\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7969\n",
      "Reward for example 1: 0.8578\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6362\n",
      "Reward for example 2: 0.7454\n",
      "Average batch reward: 0.8016\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.7125\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 57/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.6328\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8271\n",
      "Reward for example 1: 0.8790\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8057\n",
      "Reward for example 2: 0.8640\n",
      "Average batch reward: 0.8715\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.0374\n",
      "\n",
      "Processing batch 58/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.4766\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7441\n",
      "Reward for example 1: 0.8209\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8301\n",
      "Reward for example 2: 0.8811\n",
      "Average batch reward: 0.8510\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.8094\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 59/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.3477\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9097\n",
      "Reward for example 1: 0.9368\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8359\n",
      "Reward for example 2: 0.8852\n",
      "Average batch reward: 0.9110\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.8715\n",
      "\n",
      "Processing batch 60/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.8398\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8853\n",
      "Reward for example 1: 0.9197\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9307\n",
      "Reward for example 2: 0.9515\n",
      "Average batch reward: 0.9356\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.5280\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 61/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.9258\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8730\n",
      "Reward for example 1: 0.9111\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8691\n",
      "Reward for example 2: 0.9084\n",
      "Average batch reward: 0.9098\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.4813\n",
      "\n",
      "Processing batch 62/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 7.9180\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6226\n",
      "Reward for example 1: 0.7358\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6538\n",
      "Reward for example 2: 0.7577\n",
      "Average batch reward: 0.7467\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.9126\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 63/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.3613\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8623\n",
      "Reward for example 1: 0.9036\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9160\n",
      "Reward for example 2: 0.9412\n",
      "Average batch reward: 0.9224\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.1781\n",
      "\n",
      "Processing batch 64/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 8.2891\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8662\n",
      "Reward for example 1: 0.9063\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8799\n",
      "Reward for example 2: 0.9159\n",
      "Average batch reward: 0.9111\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 7.5524\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 65/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.1094\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7056\n",
      "Reward for example 1: 0.7939\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8896\n",
      "Reward for example 2: 0.9228\n",
      "Average batch reward: 0.8583\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.5272\n",
      "\n",
      "Processing batch 66/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.1719\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8613\n",
      "Reward for example 1: 0.9029\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9375\n",
      "Reward for example 2: 0.9563\n",
      "Average batch reward: 0.9296\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.0190\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 67/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.6367\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8389\n",
      "Reward for example 1: 0.8872\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9131\n",
      "Reward for example 2: 0.9392\n",
      "Average batch reward: 0.9132\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.2342\n",
      "\n",
      "Processing batch 68/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 9.8203\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7637\n",
      "Reward for example 1: 0.8346\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.5679\n",
      "Reward for example 2: 0.6975\n",
      "Average batch reward: 0.7660\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 7.5228\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 69/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.5713\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8896\n",
      "Reward for example 1: 0.9228\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8481\n",
      "Reward for example 2: 0.8937\n",
      "Average batch reward: 0.9082\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.4271\n",
      "\n",
      "Processing batch 70/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.9766\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9150\n",
      "Reward for example 1: 0.9405\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7529\n",
      "Reward for example 2: 0.8271\n",
      "Average batch reward: 0.8838\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.5144\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 71/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.1504\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7871\n",
      "Reward for example 1: 0.8510\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8857\n",
      "Reward for example 2: 0.9200\n",
      "Average batch reward: 0.8855\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.9042\n",
      "\n",
      "Processing batch 72/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.5605\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8755\n",
      "Reward for example 1: 0.9128\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9453\n",
      "Reward for example 2: 0.9617\n",
      "Average batch reward: 0.9373\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.3372\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 73/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 6.5586\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8901\n",
      "Reward for example 1: 0.9231\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9209\n",
      "Reward for example 2: 0.9446\n",
      "Average batch reward: 0.9339\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 6.1248\n",
      "\n",
      "Processing batch 74/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.8916\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9111\n",
      "Reward for example 1: 0.9378\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8984\n",
      "Reward for example 2: 0.9289\n",
      "Average batch reward: 0.9333\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.7655\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 75/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.8438\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7959\n",
      "Reward for example 1: 0.8571\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9160\n",
      "Reward for example 2: 0.9412\n",
      "Average batch reward: 0.8992\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.3554\n",
      "\n",
      "Processing batch 76/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.7578\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8481\n",
      "Reward for example 1: 0.8937\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8340\n",
      "Reward for example 2: 0.8838\n",
      "Average batch reward: 0.8887\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.1172\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 77/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.3984\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8320\n",
      "Reward for example 1: 0.8824\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8770\n",
      "Reward for example 2: 0.9139\n",
      "Average batch reward: 0.8981\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.9504\n",
      "\n",
      "Processing batch 78/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.9980\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9419\n",
      "Reward for example 1: 0.9593\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9238\n",
      "Reward for example 2: 0.9467\n",
      "Average batch reward: 0.9530\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.8571\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 79/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.0820\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8584\n",
      "Reward for example 1: 0.9009\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9023\n",
      "Reward for example 2: 0.9316\n",
      "Average batch reward: 0.9163\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.7402\n",
      "\n",
      "Processing batch 80/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.7891\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8604\n",
      "Reward for example 1: 0.9022\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9102\n",
      "Reward for example 2: 0.9371\n",
      "Average batch reward: 0.9197\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.5650\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 81/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.6855\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9258\n",
      "Reward for example 1: 0.9480\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6602\n",
      "Reward for example 2: 0.7621\n",
      "Average batch reward: 0.8551\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.2964\n",
      "\n",
      "Processing batch 82/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.2891\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8408\n",
      "Reward for example 1: 0.8886\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8701\n",
      "Reward for example 2: 0.9091\n",
      "Average batch reward: 0.8988\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.7540\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 83/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 6.9375\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8877\n",
      "Reward for example 1: 0.9214\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8774\n",
      "Reward for example 2: 0.9142\n",
      "Average batch reward: 0.9178\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 6.3672\n",
      "\n",
      "Processing batch 84/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.2773\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6646\n",
      "Reward for example 1: 0.7652\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9233\n",
      "Reward for example 2: 0.9463\n",
      "Average batch reward: 0.8558\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.5161\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 85/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.0723\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9067\n",
      "Reward for example 1: 0.9347\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9102\n",
      "Reward for example 2: 0.9371\n",
      "Average batch reward: 0.9359\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.9395\n",
      "\n",
      "Processing batch 86/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.2969\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9014\n",
      "Reward for example 1: 0.9310\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8926\n",
      "Reward for example 2: 0.9248\n",
      "Average batch reward: 0.9279\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.9870\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 87/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.3652\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8994\n",
      "Reward for example 1: 0.9296\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8750\n",
      "Reward for example 2: 0.9125\n",
      "Average batch reward: 0.9210\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.2574\n",
      "\n",
      "Processing batch 88/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.5117\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9141\n",
      "Reward for example 1: 0.9398\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8857\n",
      "Reward for example 2: 0.9200\n",
      "Average batch reward: 0.9299\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.4058\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 89/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.8242\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9463\n",
      "Reward for example 1: 0.9624\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7891\n",
      "Reward for example 2: 0.8523\n",
      "Average batch reward: 0.9074\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.4700\n",
      "\n",
      "Processing batch 90/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.5020\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7217\n",
      "Reward for example 1: 0.8052\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9326\n",
      "Reward for example 2: 0.9528\n",
      "Average batch reward: 0.8790\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.1992\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 91/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.3633\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8730\n",
      "Reward for example 1: 0.9111\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7500\n",
      "Reward for example 2: 0.8250\n",
      "Average batch reward: 0.8681\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.7876\n",
      "\n",
      "Processing batch 92/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.9531\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7822\n",
      "Reward for example 1: 0.8476\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6621\n",
      "Reward for example 2: 0.7635\n",
      "Average batch reward: 0.8055\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.7953\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 93/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 6.1719\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6768\n",
      "Reward for example 1: 0.7737\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9224\n",
      "Reward for example 2: 0.9457\n",
      "Average batch reward: 0.8597\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 5.3059\n",
      "\n",
      "Processing batch 94/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.8828\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8022\n",
      "Reward for example 1: 0.8616\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8369\n",
      "Reward for example 2: 0.8858\n",
      "Average batch reward: 0.8737\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.3924\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 95/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.0938\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9185\n",
      "Reward for example 1: 0.9429\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6401\n",
      "Reward for example 2: 0.7481\n",
      "Average batch reward: 0.8455\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.4613\n",
      "\n",
      "Processing batch 96/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.1406\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9229\n",
      "Reward for example 1: 0.9460\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8467\n",
      "Reward for example 2: 0.8927\n",
      "Average batch reward: 0.9193\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.8066\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 97/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.8867\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9238\n",
      "Reward for example 1: 0.9467\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8574\n",
      "Reward for example 2: 0.9002\n",
      "Average batch reward: 0.9234\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.5126\n",
      "\n",
      "Processing batch 98/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.2734\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7476\n",
      "Reward for example 1: 0.8233\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9165\n",
      "Reward for example 2: 0.9416\n",
      "Average batch reward: 0.8824\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.0061\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 99/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.1328\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7676\n",
      "Reward for example 1: 0.8373\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9053\n",
      "Reward for example 2: 0.9337\n",
      "Average batch reward: 0.8855\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.6596\n",
      "\n",
      "Processing batch 100/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.2383\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8828\n",
      "Reward for example 1: 0.9180\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8887\n",
      "Reward for example 2: 0.9221\n",
      "Average batch reward: 0.9200\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.0593\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 101/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.1641\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7686\n",
      "Reward for example 1: 0.8380\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9395\n",
      "Reward for example 2: 0.9576\n",
      "Average batch reward: 0.8978\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.7385\n",
      "\n",
      "Processing batch 102/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.5371\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9150\n",
      "Reward for example 1: 0.9405\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8555\n",
      "Reward for example 2: 0.8988\n",
      "Average batch reward: 0.9197\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.4136\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 103/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.7285\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9155\n",
      "Reward for example 1: 0.9409\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8833\n",
      "Reward for example 2: 0.9183\n",
      "Average batch reward: 0.9296\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.4660\n",
      "\n",
      "Processing batch 104/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.5273\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7920\n",
      "Reward for example 1: 0.8544\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6216\n",
      "Reward for example 2: 0.7351\n",
      "Average batch reward: 0.7948\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.5981\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 105/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.7266\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9023\n",
      "Reward for example 1: 0.9316\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8008\n",
      "Reward for example 2: 0.8605\n",
      "Average batch reward: 0.8961\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.3393\n",
      "\n",
      "Processing batch 106/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.3730\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9365\n",
      "Reward for example 1: 0.9556\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9209\n",
      "Reward for example 2: 0.9446\n",
      "Average batch reward: 0.9501\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.2546\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 107/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.0176\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9189\n",
      "Reward for example 1: 0.9433\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8813\n",
      "Reward for example 2: 0.9169\n",
      "Average batch reward: 0.9301\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.8766\n",
      "\n",
      "Processing batch 108/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.8672\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6738\n",
      "Reward for example 1: 0.7717\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9092\n",
      "Reward for example 2: 0.9364\n",
      "Average batch reward: 0.8541\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.1568\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 109/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.1523\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9238\n",
      "Reward for example 1: 0.9467\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8223\n",
      "Reward for example 2: 0.8756\n",
      "Average batch reward: 0.9111\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.9611\n",
      "\n",
      "Processing batch 110/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.8965\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9160\n",
      "Reward for example 1: 0.9412\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9331\n",
      "Reward for example 2: 0.9532\n",
      "Average batch reward: 0.9472\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.6907\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 111/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.4844\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8794\n",
      "Reward for example 1: 0.9156\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7900\n",
      "Reward for example 2: 0.8530\n",
      "Average batch reward: 0.8843\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.1969\n",
      "\n",
      "Processing batch 112/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.0137\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8994\n",
      "Reward for example 1: 0.9296\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9297\n",
      "Reward for example 2: 0.9508\n",
      "Average batch reward: 0.9402\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.8334\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 113/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.1875\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9209\n",
      "Reward for example 1: 0.9446\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8945\n",
      "Reward for example 2: 0.9262\n",
      "Average batch reward: 0.9354\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.0462\n",
      "\n",
      "Processing batch 114/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.5645\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9160\n",
      "Reward for example 1: 0.9412\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9316\n",
      "Reward for example 2: 0.9521\n",
      "Average batch reward: 0.9467\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.4277\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 115/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.9961\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9404\n",
      "Reward for example 1: 0.9583\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9175\n",
      "Reward for example 2: 0.9422\n",
      "Average batch reward: 0.9503\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.7974\n",
      "\n",
      "Processing batch 116/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.0664\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8779\n",
      "Reward for example 1: 0.9146\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9014\n",
      "Reward for example 2: 0.9310\n",
      "Average batch reward: 0.9228\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.7523\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 117/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.8086\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9346\n",
      "Reward for example 1: 0.9542\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8584\n",
      "Reward for example 2: 0.9009\n",
      "Average batch reward: 0.9275\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.6051\n",
      "\n",
      "Processing batch 118/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.6094\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6621\n",
      "Reward for example 1: 0.7635\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9189\n",
      "Reward for example 2: 0.9433\n",
      "Average batch reward: 0.8534\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.0801\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 119/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.3203\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7354\n",
      "Reward for example 1: 0.8147\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8027\n",
      "Reward for example 2: 0.8619\n",
      "Average batch reward: 0.8383\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.6218\n",
      "\n",
      "Processing batch 120/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.9707\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7588\n",
      "Reward for example 1: 0.8312\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8804\n",
      "Reward for example 2: 0.9163\n",
      "Average batch reward: 0.8737\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.5955\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 121/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.2988\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7578\n",
      "Reward for example 1: 0.8305\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8203\n",
      "Reward for example 2: 0.8742\n",
      "Average batch reward: 0.8523\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.8117\n",
      "\n",
      "Processing batch 122/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.9180\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6621\n",
      "Reward for example 1: 0.7635\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9297\n",
      "Reward for example 2: 0.9508\n",
      "Average batch reward: 0.8571\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.3582\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 123/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.4785\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8735\n",
      "Reward for example 1: 0.9115\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9155\n",
      "Reward for example 2: 0.9409\n",
      "Average batch reward: 0.9262\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.2955\n",
      "\n",
      "Processing batch 124/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.1973\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9189\n",
      "Reward for example 1: 0.9433\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8999\n",
      "Reward for example 2: 0.9299\n",
      "Average batch reward: 0.9366\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.1214\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 125/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.4180\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7744\n",
      "Reward for example 1: 0.8421\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8950\n",
      "Reward for example 2: 0.9265\n",
      "Average batch reward: 0.8843\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.9068\n",
      "\n",
      "Processing batch 126/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.1289\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6953\n",
      "Reward for example 1: 0.7867\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7412\n",
      "Reward for example 2: 0.8188\n",
      "Average batch reward: 0.8028\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.1174\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 127/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.2617\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9019\n",
      "Reward for example 1: 0.9313\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9277\n",
      "Reward for example 2: 0.9494\n",
      "Average batch reward: 0.9404\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.1268\n",
      "\n",
      "Processing batch 128/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.6855\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8647\n",
      "Reward for example 1: 0.9053\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8506\n",
      "Reward for example 2: 0.8954\n",
      "Average batch reward: 0.9004\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.3183\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 129/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.9180\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8882\n",
      "Reward for example 1: 0.9217\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9414\n",
      "Reward for example 2: 0.9590\n",
      "Average batch reward: 0.9404\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.8036\n",
      "\n",
      "Processing batch 130/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.2012\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8989\n",
      "Reward for example 1: 0.9292\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8633\n",
      "Reward for example 2: 0.9043\n",
      "Average batch reward: 0.9168\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.9347\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 131/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.1152\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9434\n",
      "Reward for example 1: 0.9604\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9697\n",
      "Reward for example 2: 0.9788\n",
      "Average batch reward: 0.9696\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.0509\n",
      "\n",
      "Processing batch 132/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.2852\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9365\n",
      "Reward for example 1: 0.9556\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8989\n",
      "Reward for example 2: 0.9292\n",
      "Average batch reward: 0.9424\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.0960\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 133/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.2129\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8135\n",
      "Reward for example 1: 0.8694\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8687\n",
      "Reward for example 2: 0.9081\n",
      "Average batch reward: 0.8887\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.9667\n",
      "\n",
      "Processing batch 134/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.3984\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9199\n",
      "Reward for example 1: 0.9439\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9551\n",
      "Reward for example 2: 0.9686\n",
      "Average batch reward: 0.9562\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.2935\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 135/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.1309\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9072\n",
      "Reward for example 1: 0.9351\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7402\n",
      "Reward for example 2: 0.8182\n",
      "Average batch reward: 0.8766\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.7445\n",
      "\n",
      "Processing batch 136/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.2227\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6299\n",
      "Reward for example 1: 0.7409\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9014\n",
      "Reward for example 2: 0.9310\n",
      "Average batch reward: 0.8359\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.5299\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 137/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.3760\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7822\n",
      "Reward for example 1: 0.8476\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8906\n",
      "Reward for example 2: 0.9234\n",
      "Average batch reward: 0.8855\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.2184\n",
      "\n",
      "Processing batch 138/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.9414\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8994\n",
      "Reward for example 1: 0.9296\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8984\n",
      "Reward for example 2: 0.9289\n",
      "Average batch reward: 0.9292\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.6625\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 139/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.1367\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8975\n",
      "Reward for example 1: 0.9282\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7485\n",
      "Reward for example 2: 0.8240\n",
      "Average batch reward: 0.8761\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.6242\n",
      "\n",
      "Processing batch 140/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.4180\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9258\n",
      "Reward for example 1: 0.9480\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9150\n",
      "Reward for example 2: 0.9405\n",
      "Average batch reward: 0.9443\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.2275\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 141/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.0352\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9312\n",
      "Reward for example 1: 0.9518\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7896\n",
      "Reward for example 2: 0.8527\n",
      "Average batch reward: 0.9022\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.6407\n",
      "\n",
      "Processing batch 142/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.7051\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7656\n",
      "Reward for example 1: 0.8359\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8223\n",
      "Reward for example 2: 0.8756\n",
      "Average batch reward: 0.8558\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.1707\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 143/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.0059\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9082\n",
      "Reward for example 1: 0.9357\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8838\n",
      "Reward for example 2: 0.9187\n",
      "Average batch reward: 0.9272\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.8598\n",
      "\n",
      "Processing batch 144/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.2266\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9180\n",
      "Reward for example 1: 0.9426\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8354\n",
      "Reward for example 2: 0.8848\n",
      "Average batch reward: 0.9137\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.9481\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 145/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.5615\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8838\n",
      "Reward for example 1: 0.9187\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8936\n",
      "Reward for example 2: 0.9255\n",
      "Average batch reward: 0.9221\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.4398\n",
      "\n",
      "Processing batch 146/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.1191\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6846\n",
      "Reward for example 1: 0.7792\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9287\n",
      "Reward for example 2: 0.9501\n",
      "Average batch reward: 0.8646\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.6970\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 147/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.4980\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9111\n",
      "Reward for example 1: 0.9378\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8989\n",
      "Reward for example 2: 0.9292\n",
      "Average batch reward: 0.9335\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.3985\n",
      "\n",
      "Processing batch 148/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.6445\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.5898\n",
      "Reward for example 1: 0.7129\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9458\n",
      "Reward for example 2: 0.9621\n",
      "Average batch reward: 0.8375\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.8897\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 149/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.1816\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8672\n",
      "Reward for example 1: 0.9070\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8311\n",
      "Reward for example 2: 0.8817\n",
      "Average batch reward: 0.8944\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.0568\n",
      "\n",
      "Processing batch 150/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.3125\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7393\n",
      "Reward for example 1: 0.8175\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9429\n",
      "Reward for example 2: 0.9600\n",
      "Average batch reward: 0.8887\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.8327\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 151/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.2031\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9551\n",
      "Reward for example 1: 0.9686\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8857\n",
      "Reward for example 2: 0.9200\n",
      "Average batch reward: 0.9443\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.0247\n",
      "\n",
      "Processing batch 152/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.6035\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7402\n",
      "Reward for example 1: 0.8182\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8828\n",
      "Reward for example 2: 0.9180\n",
      "Average batch reward: 0.8681\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.1281\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 153/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.0195\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8125\n",
      "Reward for example 1: 0.8687\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9209\n",
      "Reward for example 2: 0.9446\n",
      "Average batch reward: 0.9067\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.8311\n",
      "\n",
      "Processing batch 154/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.4199\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8691\n",
      "Reward for example 1: 0.9084\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7783\n",
      "Reward for example 2: 0.8448\n",
      "Average batch reward: 0.8766\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.1213\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 155/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.2363\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7119\n",
      "Reward for example 1: 0.7983\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8975\n",
      "Reward for example 2: 0.9282\n",
      "Average batch reward: 0.8633\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.9306\n",
      "\n",
      "Processing batch 156/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.6953\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9243\n",
      "Reward for example 1: 0.9470\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7651\n",
      "Reward for example 2: 0.8356\n",
      "Average batch reward: 0.8913\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.2937\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 157/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.0625\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8955\n",
      "Reward for example 1: 0.9269\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8857\n",
      "Reward for example 2: 0.9200\n",
      "Average batch reward: 0.9234\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.7515\n",
      "\n",
      "Processing batch 158/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.7871\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9229\n",
      "Reward for example 1: 0.9460\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7812\n",
      "Reward for example 2: 0.8469\n",
      "Average batch reward: 0.8964\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.3949\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 159/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.8398\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8418\n",
      "Reward for example 1: 0.8893\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8140\n",
      "Reward for example 2: 0.8698\n",
      "Average batch reward: 0.8795\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.2567\n",
      "\n",
      "Processing batch 160/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.2158\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9482\n",
      "Reward for example 1: 0.9638\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9355\n",
      "Reward for example 2: 0.9549\n",
      "Average batch reward: 0.9593\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.1664\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 161/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.0684\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 805 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 805])\n",
      "Entailment score: 0.9224\n",
      "Reward for example 1: 0.9457\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 805])\n",
      "Entailment score: 0.7070\n",
      "Reward for example 2: 0.7949\n",
      "Average batch reward: 0.8703\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.6704\n",
      "\n",
      "Processing batch 162/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.2090\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9390\n",
      "Reward for example 1: 0.9573\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9277\n",
      "Reward for example 2: 0.9494\n",
      "Average batch reward: 0.9533\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.1059\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 163/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.2070\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8740\n",
      "Reward for example 1: 0.9118\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9375\n",
      "Reward for example 2: 0.9563\n",
      "Average batch reward: 0.9340\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.9955\n",
      "\n",
      "Processing batch 164/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 5.0703\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.5967\n",
      "Reward for example 1: 0.7177\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9512\n",
      "Reward for example 2: 0.9658\n",
      "Average batch reward: 0.8417\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 4.2679\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 165/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.1094\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6724\n",
      "Reward for example 1: 0.7707\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8232\n",
      "Reward for example 2: 0.8763\n",
      "Average batch reward: 0.8235\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.5605\n",
      "\n",
      "Processing batch 166/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.6777\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9297\n",
      "Reward for example 1: 0.9508\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9312\n",
      "Reward for example 2: 0.9518\n",
      "Average batch reward: 0.9513\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.5960\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 167/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.1865\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7256\n",
      "Reward for example 1: 0.8079\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8428\n",
      "Reward for example 2: 0.8899\n",
      "Average batch reward: 0.8489\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.0073\n",
      "\n",
      "Processing batch 168/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.8457\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8867\n",
      "Reward for example 1: 0.9207\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9263\n",
      "Reward for example 2: 0.9484\n",
      "Average batch reward: 0.9345\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.7249\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 169/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.2148\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8169\n",
      "Reward for example 1: 0.8718\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9248\n",
      "Reward for example 2: 0.9474\n",
      "Average batch reward: 0.9096\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.0146\n",
      "\n",
      "Processing batch 170/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.1035\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9570\n",
      "Reward for example 1: 0.9699\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9380\n",
      "Reward for example 2: 0.9566\n",
      "Average batch reward: 0.9633\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.0262\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 171/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.5156\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9175\n",
      "Reward for example 1: 0.9422\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9043\n",
      "Reward for example 2: 0.9330\n",
      "Average batch reward: 0.9376\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.3587\n",
      "\n",
      "Processing batch 172/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.9980\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9473\n",
      "Reward for example 1: 0.9631\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9434\n",
      "Reward for example 2: 0.9604\n",
      "Average batch reward: 0.9617\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.8833\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 173/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.0684\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 949 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 949])\n",
      "Entailment score: 0.9268\n",
      "Reward for example 1: 0.9487\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 949])\n",
      "Entailment score: 0.8643\n",
      "Reward for example 2: 0.9050\n",
      "Average batch reward: 0.9269\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.8439\n",
      "\n",
      "Processing batch 174/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.8477\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6602\n",
      "Reward for example 1: 0.7621\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9482\n",
      "Reward for example 2: 0.9638\n",
      "Average batch reward: 0.8629\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.4574\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 175/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.8223\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7822\n",
      "Reward for example 1: 0.8476\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8887\n",
      "Reward for example 2: 0.9221\n",
      "Average batch reward: 0.8848\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.3820\n",
      "\n",
      "Processing batch 176/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.5273\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6309\n",
      "Reward for example 1: 0.7416\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9043\n",
      "Reward for example 2: 0.9330\n",
      "Average batch reward: 0.8373\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.9535\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 177/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.9160\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 986 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 986])\n",
      "Entailment score: 0.7432\n",
      "Reward for example 1: 0.8202\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 986])\n",
      "Entailment score: 0.6411\n",
      "Reward for example 2: 0.7488\n",
      "Average batch reward: 0.7845\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.0721\n",
      "\n",
      "Processing batch 178/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.0410\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9531\n",
      "Reward for example 1: 0.9672\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6426\n",
      "Reward for example 2: 0.7498\n",
      "Average batch reward: 0.8585\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.6107\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 179/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.3945\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7515\n",
      "Reward for example 1: 0.8260\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9072\n",
      "Reward for example 2: 0.9351\n",
      "Average batch reward: 0.8805\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.9890\n",
      "\n",
      "Processing batch 180/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.6953\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9375\n",
      "Reward for example 1: 0.9563\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8418\n",
      "Reward for example 2: 0.8893\n",
      "Average batch reward: 0.9228\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.4099\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 181/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.4473\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9219\n",
      "Reward for example 1: 0.9453\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8145\n",
      "Reward for example 2: 0.8701\n",
      "Average batch reward: 0.9077\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.1291\n",
      "\n",
      "Processing batch 182/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.9238\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9307\n",
      "Reward for example 1: 0.9515\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7310\n",
      "Reward for example 2: 0.8117\n",
      "Average batch reward: 0.8816\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.5776\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 183/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.5781\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9482\n",
      "Reward for example 1: 0.9638\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9121\n",
      "Reward for example 2: 0.9385\n",
      "Average batch reward: 0.9511\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.4521\n",
      "\n",
      "Processing batch 184/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.3945\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.6470\n",
      "Reward for example 1: 0.7529\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8184\n",
      "Reward for example 2: 0.8729\n",
      "Average batch reward: 0.8129\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.9464\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 185/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.5254\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9541\n",
      "Reward for example 1: 0.9679\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7026\n",
      "Reward for example 2: 0.7918\n",
      "Average batch reward: 0.8799\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.3421\n",
      "\n",
      "Processing batch 186/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.6641\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7622\n",
      "Reward for example 1: 0.8335\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9150\n",
      "Reward for example 2: 0.9405\n",
      "Average batch reward: 0.8870\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.3631\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 187/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.0469\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9590\n",
      "Reward for example 1: 0.9713\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7207\n",
      "Reward for example 2: 0.8045\n",
      "Average batch reward: 0.8879\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.8174\n",
      "\n",
      "Processing batch 188/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.3965\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9067\n",
      "Reward for example 1: 0.9347\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7422\n",
      "Reward for example 2: 0.8195\n",
      "Average batch reward: 0.8771\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.1020\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 189/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 4.3281\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9644\n",
      "Reward for example 1: 0.9750\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8184\n",
      "Reward for example 2: 0.8729\n",
      "Average batch reward: 0.9240\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.9990\n",
      "\n",
      "Processing batch 190/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.8027\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9053\n",
      "Reward for example 1: 0.9337\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9189\n",
      "Reward for example 2: 0.9433\n",
      "Average batch reward: 0.9385\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.5688\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 191/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.6191\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8140\n",
      "Reward for example 1: 0.8698\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9277\n",
      "Reward for example 2: 0.9494\n",
      "Average batch reward: 0.9096\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.2920\n",
      "\n",
      "Processing batch 192/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.9707\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7334\n",
      "Reward for example 1: 0.8134\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9111\n",
      "Reward for example 2: 0.9378\n",
      "Average batch reward: 0.8756\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.4767\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 193/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.1719\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8999\n",
      "Reward for example 1: 0.9299\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8633\n",
      "Reward for example 2: 0.9043\n",
      "Average batch reward: 0.9171\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.9919\n",
      "\n",
      "Processing batch 194/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.2285\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8965\n",
      "Reward for example 1: 0.9275\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7173\n",
      "Reward for example 2: 0.8021\n",
      "Average batch reward: 0.8648\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.9273\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 195/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.9180\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8486\n",
      "Reward for example 1: 0.8940\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.7471\n",
      "Reward for example 2: 0.8229\n",
      "Average batch reward: 0.8585\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.5051\n",
      "\n",
      "Processing batch 196/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.9434\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 876 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 876])\n",
      "Entailment score: 0.8242\n",
      "Reward for example 1: 0.8770\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 876])\n",
      "Entailment score: 0.9399\n",
      "Reward for example 2: 0.9580\n",
      "Average batch reward: 0.9175\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.7004\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 197/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 1.6650\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 956 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 956])\n",
      "Entailment score: 0.9434\n",
      "Reward for example 1: 0.9604\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 956])\n",
      "Entailment score: 0.8984\n",
      "Reward for example 2: 0.9289\n",
      "Average batch reward: 0.9446\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.5728\n",
      "\n",
      "Processing batch 198/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.0859\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9424\n",
      "Reward for example 1: 0.9597\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.8413\n",
      "Reward for example 2: 0.8889\n",
      "Average batch reward: 0.9243\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 1.9280\n",
      "Updating weights...\n",
      "\n",
      "Processing batch 199/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 2.9238\n",
      "Generating summaries for reward calculation...\n",
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9331\n",
      "Reward for example 1: 0.9532\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 1024])\n",
      "Entailment score: 0.9292\n",
      "Reward for example 2: 0.9504\n",
      "Average batch reward: 0.9518\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 2.7829\n",
      "\n",
      "Processing batch 200/200 in epoch 1\n",
      "Running forward pass...\n",
      "Loss: 3.6914\n",
      "Generating summaries for reward calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 964 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rewards...\n",
      "Calculating rewards for batch of size 2\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 964])\n",
      "Entailment score: 0.7373\n",
      "Reward for example 1: 0.8161\n",
      "Computing entailment score. Input shape: torch.Size([1, 4096]), Summary shape: torch.Size([1, 964])\n",
      "Entailment score: 0.8740\n",
      "Reward for example 2: 0.9118\n",
      "Average batch reward: 0.8640\n",
      "Calculating reward-weighted loss...\n",
      "Reward-weighted loss: 3.1892\n",
      "Updating weights...\n",
      "Saving LoRA model after epoch 1 to ./legal-led-lora-output/epoch-1\n",
      "Epoch 1 metrics: Loss=2.0594, Reward=0.8916\n",
      "\n",
      "==================================================\n",
      "TRAINING COMPLETE\n",
      "==================================================\n",
      "Saving final LoRA model to ./legal-led-lora-output/final-model\n",
      "\n",
      "==================================================\n",
      "TESTING MODEL ON 3 EXAMPLES\n",
      "==================================================\n",
      "\n",
      "Processing test example 1/3\n",
      "Tokenizing input...\n",
      "Generating summary...\n",
      "\n",
      "Example 1:\n",
      "Original document (truncated): iminal Appeal No. 47 of 1963.\n",
      "Appeal by special leave from the judgment and order, dated January 29, 1963 of the Allahabad High Court in Criminal Appeal No. 998 of 1962.\n",
      "M. K. Ramamurthi, section C. A...\n",
      "Original summary: The appellant published in his paper, which had a circulation mainly in Aligarh, a statement to the effect that Public Prosecutors and Assistant Public Prosecutors had been receiving bribes.\n",
      "The Public Prosecutor and the 11 Assistant Public Prosecutors at Aligarh obtained the sanction of the State Government as required under section 198B(c) of Code of Criminal Procedure to file a complaint under section 500 Indian Penal Code in a court of Sessions against the appellant for publishing defamatory remarks against the Assistant Public Prosecutor S, of District Aligarh and other police prosecuting staff of the Government in respect of their conduct in the discharge of public functions.\n",
      "The Sessions Judge convicted the appellant and the High Court dismissed his appeal against the conviction.\n",
      "It was contended on behalf of the appellant, inter alia, that the sanction granted under section 198B(c) was not the sanction contemplated by law because it was a general sanction and not with respect to the defamation of any particular Public Prosecutor or Assistant Public Prosecutor; for the purpose of an offence under section 500 Indian Penal Code the person defamed must be an individual or a particular group and there was no evidence that the remarks were defamatory of any particular group; that the prosecution did not lead any evidence to establish that the defamed group had any reputation which could be harmed; and that in any event the remarks were for public good.\n",
      "HELD : (i) the sanction given by the Government was specifically with respect to the defamation of S, the Assistant Public Prosecutor, Aligarh, and the other prosecuting staff of the Government and as such it could not be considered a general sanction not contemplated by law.\n",
      "[826 H] The sanction given, could be taken to be sanction in respect of the defamation of the entire Prosecution staff in the State; there was therefore no force in the contention that the Public Prosecutor Was not competent to restrict his complaint to the defamation of S, and other Public Prosecuting staff of the State Government at Aligarh.\n",
      "Furthermore, although the impugned article did not contain any express reference to the prosecuting staff at Aligarh, the offending remarks could properly be taken to refer to the prosecuting staff at Aligarh in the context of the paper being a local weekly and the other circumstances of the case.\n",
      "[827 C E] (ii) Explanation II to section 499 makes it clear that there can be a defamation of an individual person and also of a 'collection of persons '.\n",
      "Such a collection of persons must be identifiable in the sense, that one could with cartainty say that the particular group had been defamed as dis tinguished from the rest of the community.\n",
      "The prosecuting staff of Aligarh, and even the prosecuting staff in the State of U.P. would be such an identifiable group or 'collection of persons '.\n",
      "[827 G H; 828 A C] Supp/. 65 6 824 (iii) The impugned remarks were per se defamatory of the group of persons referred to.\n",
      "The tenor of the article did not indicate that the purpose of the appellant in publishing these remarks was \"public good\".\n",
      "No enquiry could have been started by that Government on such a publication implying the acceptance of bribes by the prosecuting staff.\n",
      "The impugned remarks could lead readers to believe or suspect that the Public Prosecutors were corrupt and thus affected the reputation of the prosecuting staff adversely.\n",
      "Unless proved otherwise, the presumption is that every person has a good reputation.\n",
      "[828 E H] The lower courts were therefore right in rejecting the contention that the impugned remarks were protected under Exceptions 3 and 9 to section 499 I.P.C. and in convicting the appellant.\n",
      "[829 B D]\n",
      "\n",
      "Generated summary: The appellant published an article in his paper 'Kaliyug ' dated September 12, 1960 containing defamatory remarks against the Assistant Public Prosecutor and other police prosecuting staff of the Government in respect of their conduct in the discharge of public functions.\n",
      "The Public Prosecutor and the eleven Assistant Public Prosecutors at Aligarh requested the Superintendent of Police for obtaining the sanction of the Government for filing a complaint under section 500 Indian Penal Code in the Court of the Sessions Judge under section 500 I.P.C.\n",
      "The Government was duly approached through proper channel and ultimately the Home Secretary, U.P. Government wrote to the Inspector General U.P., on March 1, 1961, directing the State Government to convey the sanction to the State Government under section 198B(c) of the Code of Criminal Procedure to the filing of a complaint in a Court of Sessions against the appellant with respect to the defamation of two persons (i) the Assistant Public prosecutor and the other Police prosecuting staff of Government of Uttar Pradesh, which would be the entire prosecuting staff in the State.\n",
      "The appellant admitted before the Sessions Judge that he had published the article for the good of the public and that he published it in most general terms to bring bad things to the notice of the Government and the authorities for the public good.\n",
      "The Sessions Judge convicted him of the offence under section 500 Penal Code holding that the aforesaid statements in the article were defamatory and that the appellant was not protected by exceptions 3 and 9 to section 499 Penal Code.\n",
      "His appeal against the conviction was dismissed by the High Court.\n",
      "In appeal to this Court it was contended on behalf of the appellant that (1) there was no proof that the Government bad sanctioned the lodging of the complaint, (2) the charge framed was the one for which sanction was granted or the requisite complaint was filed, and (3) the sanction suffered from any defect, and (4) that the sanction was not granted with respect to any particular person and that it was not contemplated by law that the Public Prosecutor or the Assistant Public Prosecutors could not be said to have defamed any particular group of persons and that there was no evidence to establish that there was any defamatory statement in the article as to restrict the imputation to the staff of the appellant alone and when the remarks could be properly taken to be with reference to the prosecuting staff at Aligarah in the context of 'Kaliyaug ' being a local weekly and the desire of the Editor to make public all these matters in a Court in proceedings to be started by the appellant in view of certain matter published about him in an earlier issue of the paper.\n",
      "Allowing the appeal, HELD: (1) The sanction suffered from no defect.\n",
      "It is essential for the purpose of an offence under s.500 Penal Code that the person defamed must be an individual or an individual.\n",
      "Section 499 Penal Code provides that no court shall take cognizance of an offence falling under Chapter XXI (which contains sections 499 and 500 Penal Code) except upon complaint made by some person aggrieved by such offence.\n",
      "The language of Explanation 2 is general and any collection of persons would be covered by it.\n",
      "Sub section 198B, however, is an exception to the provisions of section 198 and provides that notwithstanding anything contained in the Code, when any offence falling under chapter XXI of the Indian Penal Code other than the offence of defamation by spoken words is alleged to have been committed against any public servant employed in connection with the affairs of a State, in respect of his conduct in discharge of his public functions, a Court of Session may take cognisance of such offence without the accused being committed to it for trial, upon a complaint in writing made by the Public Prosecutor.\n",
      "This group consists of all members of the prosecution staff in the service of the Government of U. P. There is again an identifiable group of prosecuting staff, consisting of Public Prosecutors and Assistant Public Prosecutors, at Aligargarh.\n",
      "The impugned remarks are per se defamatory of the group of persons referred to.\n",
      "The defence in the Courts below was that they were for public good and the appellant was protected under Exceptions 3 and 9, of section 499 Penal code.\n",
      "The tenor of the article does not indicate that the purpose of the appellant in publishing these remarks was 'public good '.\n",
      "According to the article.\n",
      "the appellant would have welcomed the opportunity that would be offered by the case contemplated against him by R. K. Sharma, to make public the impugned matters.\n",
      "His remarks therefore could have the tendency to dissuade R.K. Sharma from instituting the proceedings for fear of giving greater currency to untrue allegations which be not favourable to him or to the prosecution staff at aligarh or in the State, and by themselves could not render any public good.ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚No enquiry could have been started by the Government on such a publication implying the passing of money from the pockets of certain set of people to the pockets of the prosecuting\n",
      "\n",
      "Processing test example 2/3\n",
      "Tokenizing input...\n",
      "Generating summary...\n",
      "\n",
      "Example 2:\n",
      "Original document (truncated): minal Appeal No. 210 of 1963.\n",
      "Appeal by special leave from the judgment and order dated July 27, 1963, of the Madhya Pradesh High Court (Gwalior Bench) in Criminal Appeal No. 83 of 1963 and Criminal R...\n",
      "Original summary: On the first information report lodged by the appellant, the corpse of his step son was recovered.\n",
      "The police arrested three other persons indicated to be the culprits, but as a result of the investigation, the appellant (1) A.I.R. 1961 Orissa, 131.\n",
      "313 was sent up for trial for the murder and sentenced to death.\n",
      "The High Court confirmed the conviction and sentence.\n",
      "On appeal by special leave it was contended that the first information report was inadmissible in evidence and should not have been, therefore, taken on the record.\n",
      "Held:There was no force in the contention.\n",
      "The report was neither confession of the accused nor a statement made to a police officer during the course of investigation.\n",
      "Section 25 of the Evidence Act and section 162 of the Code of Criminal Procedure do not bar its admissibility.\n",
      "The report was an admission by the accused of certain facts which had a bearing on the question to be determined by the Court viz., how and by whom the murder was committed or whether the accused 's statement in court denying the correctness of certain statements of the prosecution witnesses was correct or not.\n",
      "Admissions ire admissible in evidence under section 21 of the Evidence admission of an accused can be proved against him.\n",
      "Dal singh vs King Emperor, L. R. 44 I.A. 137, applied.\n",
      "Nisar Ali vs State of U.P. , considered and distinguished.\n",
      "State vs Balachand A.I.R. 1960 Raj. 101, State of Rajasthan V. shiv Singh A.I.R. 1962 Raj. 3 and Allohdia vs State, 1959 All.\n",
      "L.J. 340, referred to.\n",
      "\n",
      "Generated summary: As a result of the investigation, the appellant and one Banwari were sent up for trial for the murder of Gulab.\n",
      "The police knew nothing of the offence till 9 p.m. on January 20, 1963, when the appellant himself went to the police station, Saroichhola, and lodged a first information report stating therein that on peeping into the well near the peepul tree of Hadpai on the morning of January 20, 1962, he found his son lying dead in the well.\n",
      "The Sessions Judge and the High Court considered the appellant 's statements in this report which went to explain his separation from Gulab on account of the conduct of Ramle and others and came to the conclusion that those statements were false.\n",
      "This was in a way justified as the burden lay on the appellant to account for the disappearance of Gulab when he had stated that he had taken him away.\n",
      "The High Court also took into consideration the fact that the deceased was wearing the pair of shorts recovered at the time he was taken away.\n",
      "In appeal to this Court it was contended on behalf of the appellant that the first information report was inadmissible in evidence and should not have been therefore taken on the record.\n",
      "On behalf of the prosecution it was contended that the report was not a confession of the appellant.\n",
      "It was not a statement made to a police officer during the course of investigation.\n",
      "The report was an admission by the accused of certain facts which had a bearing on the question to be determined by the Court viz., how and by whom the murder was committed, or whether the appellant \"s statement in court denying the correctness of certain statements of the prosecution witnesses was correct or not.\n",
      "The objection to the admissibility of the first informa tion report lodged by the appellant was not sound and the Courts below had rightly admitted it in evidence and had made proper use of it.\n",
      "The circumstances held established by the High Court were sufficient to reach the conclusion that Gulab was murdered by the appellant who was the last person in whose company the deceased was seen alive and who knew where the dead body lay and who gave untrue explanation about his knowing it in the report lodged by him and gave no explanation in Court as to how he separated from the deceased.\n",
      "HELD: (i) Admissions of an accused can be proved against him under section 21 of the Evidence Act.\n",
      "Section 17 defines an admission to be a statement, oral or documentary, which suggests any inference as to any fact in issue or relevant fact, and which is made by any of the persons, and under the circumstances, thereafter mentioned, in the Act.\n",
      "(ii)Section 21 provides that admissions are relevant and may be proved as against a person who makes them.\n",
      "(iii)The first information report is not a confessional statement of the accused.\n",
      "It is the usual first information report an aggrieved person or someone on his behalf lodges against the alleged murderers.\n",
      "(iv)Such a distinction, if any, has no bearing on the issue of the admissible of the report.\n",
      "(v)The report was held admissible because it was not a 'confession ' and it was helpful in determining the matter before the Court.\n",
      "(vi)It was in no sense a confession.\n",
      "As appears from its terms it was rather in the nature of an information or charge laid against Mohan and Jhunni in respect of the assault alleged to have been made on Dal Singh on his way from Hardua to Jubbulpore.\n",
      "As such the statement is proper evidence against him.\n",
      "[vii](vii)It is not correct to say that the expression 'first information report ' cannot be used as evidence as evidence at the trial if he becomes an accused if he becomes accused.\n",
      "(ix)A confessional first information report cannot be used against the maker when he be an accused and necessarily can be used against a co accused.\n",
      "Nisar Ali vs State of U.P. [1957] S.C.R. 657, referred to.\n",
      "\n",
      "\n",
      "Processing test example 3/3\n",
      "Tokenizing input...\n",
      "Generating summary...\n",
      "\n",
      "Example 3:\n",
      "Original document (truncated): Civil Appeal No. 2618 of 1983.\n",
      "From the Judgment and Order dated the 18th January, 1983 of the Patna High Court in Election Petition No. 15 of 1980.\n",
      "section Rangarajan, D. P. Mukherjee, G. section Cha...\n",
      "Original summary: The first respondent who lost to the appellant by 24 votes in the Assembly Elections filed an election petition in the High Court under section 81 of the Representation of the People Act, 1951 asking for the appellant 's election to be set aside and for declaration that he should be declared as the successful candidate.\n",
      "In para 9(i) of the petition the respondent pleaded that 74 ballot papers cast in his favour were wrongly rejected on the ground that they did not contain the signature of the Presiding Officer.\n",
      "The High Court ordered inspection of these ballot papers.\n",
      "The High Court held that the rejection of these 74 ballot papers for want of the Presiding Officer 's signature was not justified and gave the respondent No. 1 credit of all those votes and on that basis while setting aside the election of the appellant, declared the first respondent to have been duly elected.\n",
      "Hence this appeal.\n",
      "The appellant urged that the pleading in para 9(i) of the Election petition did not amount to a concise statement of the material facts as required by law; the High Court went wrong in allowing inspection of the ballot papers; the 74 ballot papers in dispute did not contain the signature of the presiding officer and were rightly rejected at the counting in view of the mandatory provision in rule 56(2) of the Conduct of Elections Rules, 1961 and the High Court 's view that in the absence of a prayer for recrimination under section 97 of the Act, the appellant was precluded from asking for a recount of the other rejected ballot papers is not tenable in law.\n",
      "Dismissing the appeal, HELD: An election petition is presented in terms of section 81 of the Act.\n",
      "Section 83 prescribed as to what the petition should contain.\n",
      "Clause (a) of sub section\n",
      "(1) of section 83 states that an election petition shall contain a concise statement of the material facts on which the petitioner relies.\n",
      "In the instant 119 case the number of ballot papers alleged to have been wrongly rejected has been furnished, the counting table number has been given, the booth number has also been disclosed and the ground for rejection has even been pleaded.\n",
      "The only specific detail which was wanting was the serial number of the ballot papers.\n",
      "This particular was not available to the election petitioner in spite of attempts made on his behalf.\n",
      "The Court, therefore, agrees with the High Court that in the facts and circumstances of the case the pleading in paragraph 9(i) set out the material facts in a proper way and no defect can be found with it.\n",
      "The High Court had rightly ordered the inspection of the ballot papers.\n",
      "[126 B C; H; 127 A; 128 F G; 127 F] Samant N. Balakrishan etc., vs George Fernandez and Ors, etc.; , explained and distinguished, Bhabhi vs Sheo Govind and Ors., [1975] Suppl.\n",
      "S.C.R. 202, referred to.\n",
      "Rule 38(1) of the Conduct of Election Rules, 1961 provides inter alia that every ballot paper before it is issued to an elector shall be stamped on the back with a distinguishing mark and shall be signed in full on its back by the presiding officer.\n",
      "The distinguishing mark can be put by anyone but the signature has got to be of the presiding officer and obviously he has to personally do that job.\n",
      "Rule 56(2)(h) provides that the returning officer shall reject a ballot paper if it does not bear both the distinguishing mark and the signature as mentioned in sub rule (1) of rule 38.\n",
      "There is a proviso to sub rule (2) of rule 56 which says that where the returning officer is satisfied that any such defect as is mentioned in clause (h) has been caused by any mistake or failure on the part of a presiding officer or polling officer, the ballot paper shall not be rejected merely on the ground of such defect.\n",
      "The proviso, once it is applicable is a mandate that the ballot paper is not to be rejected.\n",
      "[129 F G; 130 G; 129 E F; 130 E; 131 H] In the instant case the 74 ballot papers in dispute were rejected because they did not contain the signature of the presiding officer as required under rule 38(1).\n",
      "To see whether the proviso to sub rule (2) of rule 56 was applicable, it has to be found out whether the absence of the signature of the presiding officer on these ballot papers was on account of mistake or of his failure.\n",
      "On the submissions at the bar, the question of mistake does not arise.\n",
      "It was the obligation of the presiding officer to put his signature on the ballot papers before they were issued to the voters.\n",
      "Every voter has the right to vote and in the democratic set up prevailing in the country no person entitled to share the franchise can be denied the privilege.\n",
      "Nor can the candidate be made to suffer.\n",
      "Keeping this position in view the Court is of the definite view that the present case is one of the failure on the part of the presiding officer, who had been taken ill on the date of poll and was away from the place of polling for quite some time, to put his signature on those ballot papers so as to satisfy the requirement of law.\n",
      "The ballot papers therefore were not liable to be rejected as the proviso applied and the High Court came to the correct conclusion in counting these ballot papers and giving credit thereof to the respondent No. 1.\n",
      "[130 C; F G; 131 F H; 130 H; 131 E; H; 132 A] 120 In a case in which the election petition claims that the election of the returned candidate is void, and also asks for a declaration that the petitioner himself or some other person has been duly elected, section 100 as well as section 101 of the Act would apply, and it is in respect of the additional claim for such declaration that section 97 comes into play.\n",
      "Section 97(1) thus allows the returned candidate to recriminate and raise pleas in support of his case that the other person in whose favour a declaration is claimed by the petition cannot be said to be validity elected, and these would be pleas of attack and it would be open to the returned candidate to take these pleas, because when he recriminates, he really becomes a counter petitioner challenging the validity of the election of the alternative candidate.\n",
      "The result of section 97(1) therefore is that in dealing with a composite election petition, the Tribunal enquires into not only the case made out by the petitioner, but also the counter claim made by the returned candidate.\n",
      "That being the nature of the proceedings contemplated by section 97(1), it is not surprising that the returned candidate is required to make his recrimination and serve notice in that behalf in the manner and within the time specified by section 97(1) proviso and section 97(2).\n",
      "If the returned candidate does not recriminate as required by section 97, then he cannot make any attack against the alternative claim made by the petition.\n",
      "[135 A F] Kum.\n",
      "Shradha Devi vs Krishna Chandra Pant & Ors.\n",
      ", ; ; Jabar Singh vs Genda Lal, ; and P. Malaichami vs M. Andi Ambalam & Ors. ; referred to.\n",
      "In the instant election petition two reliefs had been claimed, firstly, for setting aside the election of the returned candidate, i.e. the appellant, and secondly, for a declaration that the election petitioner (respondent No. 1) was the duly elected candidate.\n",
      "The relief claimed was in terms of section 100(1)(d) (iii) and section 101(a) of the Act.\n",
      "Admittedly no application for recrimination was filed by the appellant.\n",
      "In the absence of a recrimination petition conforming to the requirement of section 97 of the Act the appellant who happens to be an advocate and is presumed to know the law, was not entitled to combat the claim of the election petitioner on the ground that if the remaining rejected ballot papers had been counted the election petitioner would not have been found to have polled the majority of the valid votes.\n",
      "[132 D E; 133 A; 138 C D]\n",
      "\n",
      "Generated summary: The appellant was declared elected to the Bihar Legislative Assembly on May 31, 1980 on the ground that he had received 24 more votes than the respondent No. 1.\n",
      "Respondent No. 1 filed an election petition under section 81 of the Representation of the People Act, 1951 asking for the appellant 's election to be set aside and for a declaration that he should be declared as the successful candidate.\n",
      "The appellant pleaded that he would be quite satisfied if only 74 rejected ballot papers from 124 booth No. 10 were inspected.\n",
      "The trial court held that the rejection of these 74 ballot papers for want of the Presiding Officer 's signature was not justified and gave the election petitioner credit of all those votes.\n",
      "The High Court did not take into account the plea in regard to 31 ballot papers in the absence of particulars.\n",
      "In appeal to this Court, it was contended on behalf of the appellant that (i) the particulars furnished in paragraph 9 of the election petition were inadequate and fell short of the requirements of the law; (ii) inspection of the ballot papers should not have been granted and even on inspection, the 74 ballot papers were not available to be counted in favour of respondent No.1; (iii) if inspection was to be granted and credit was to be given of rejected ballot papers, all the papers should have been scrutinised and the examination for recount should have been confined to 74 only; and (iv) the view taken by the trial court that in the absence Of a prayer for recrimination under section 97 of the Act, the appellant was precluded from asking for a recount of the other rejected ballot papers was not tenable in law.\n",
      "Allowing the appeal, ^ HELD: 1.\n",
      "An election petition is not an action at law or a suit in equity.\n",
      "It is a statutory proceeding to which neither the common law nor the principles of equity apply but only those rules which the statute makes and applies.\n",
      "Concepts familiar to Common Law and Equity must remain strangers to Election Law unless statutorily embodied.\n",
      "A Court has no right to resort to them on considerations of alleged policy because policy in such matters, as those relating to the trial of election disputes, is what the statute lays down.\n",
      "In the trial of an election dispute, court is put in a straight jacket.\n",
      "Thus the entire election process commencing from the issuance of the notification calling upon a constituency to elect a member or members right up to the final resolution of the dispute, if any, concerning the election is regulated by the Representation Act, 1951, different stages of the process being dealt with by different provisions of the Act.\n",
      "There can be no election to Parliament or the State Legislature except as provided by the Act and again, no such election may be questioned except in the manner provided by Act.\n",
      "The Representation of People Act has been held to be a complete and self contained code within which must be found any right claimed in relation to an election or an election dispute.\n",
      "[127F H; 128A B] 2.\n",
      "The plea in paragraph 9(i) of the Election Petition set out the material facts in a proper way and no defect can be found with it.\n",
      "In view of the statement of the counting agent of Respondent No.1 and the evidence of the Assistant Returning Officer, there can be no scope to doubt, and in our view the High Court was right in taking the view, that the particulars of the rejected ballot papers are not available to the counting agents and, therefore, particulars of the numbers of the ballot paper had not been given in the election petition.\n",
      "[128B C] 3.\n",
      "The pleading in paragraph 9 (i) set out the materials facts in proper way and there is no defect in the plea.\n",
      "It was, therefore, right in the facts and circumstances of the case, that the pleading in the pleadings set out these material facts and no defect could be found.\n",
      " [128C D] 4.\n",
      "Bhabhi vs Sheo Govind & Ors., ; , followed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM, \n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig, \n",
    "    TaskType, \n",
    "    get_peft_model,\n",
    "    PeftModel,\n",
    "    PeftConfig\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import kl_div, log_softmax, softmax\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import gc\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths and parameters\n",
    "MODEL_PATH = '/kaggle/input/rl-legal-summarizer-model/legal-led-lora-output/final-model'\n",
    "OUTPUT_DIR = \"./legal-led-lora-output\"\n",
    "MAX_INPUT_LENGTH = 4096  # LED model supports up to 16384 tokens\n",
    "MAX_OUTPUT_LENGTH = 1024  # Adjust based on your summary lengths\n",
    "BATCH_SIZE = 2  # Can increase with LoRA\n",
    "GRADIENT_ACCUMULATION_STEPS = 2  # Reduced as memory is less of an issue\n",
    "LEARNING_RATE = 2e-4  # Typically higher for LoRA\n",
    "NUM_EPOCHS = 1\n",
    "ENTAILMENT_WEIGHT = 0.7  # Weight for entailment in reward function\n",
    "KL_WEIGHT = 0.3  # Weight for KL divergence in reward function\n",
    "SAVE_STEPS = 500\n",
    "EVAL_STEPS = 500\n",
    "\n",
    "# LoRA specific parameters\n",
    "LORA_RANK = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT = 0.1\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def load_models_and_tokenizer():\n",
    "    \"\"\"Load model with LoRA and tokenizer.\"\"\"\n",
    "    print(\"Loading model and tokenizer with LoRA configuration...\")\n",
    "    \n",
    "    try:\n",
    "        # Load tokenizer first\n",
    "        tokenizer = AutoTokenizer.from_pretrained('nsi319/legal-led-base-16384')\n",
    "        \n",
    "        # Load the main model with reduced precision to save memory\n",
    "        base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            MODEL_PATH,\n",
    "            torch_dtype=torch.float16,  # Use lower precision\n",
    "        )\n",
    "        base_model.gradient_checkpointing_enable()  # Add this line to save more memory\n",
    "        base_model = base_model.to(device)  # Move to GPU manually\n",
    "                \n",
    "        # Configure LoRA\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "            inference_mode=False,\n",
    "            r=LORA_RANK,\n",
    "            lora_alpha=LORA_ALPHA,\n",
    "            lora_dropout=LORA_DROPOUT,\n",
    "            # Target specific attention layers for efficiency\n",
    "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"out_proj\", \"fc1\", \"fc2\"],\n",
    "        )\n",
    "        \n",
    "        # Create model with LoRA adapter\n",
    "        model = get_peft_model(base_model, peft_config)\n",
    "        \n",
    "        # Print trainable parameters vs total parameters for verification\n",
    "        model.print_trainable_parameters()\n",
    "            \n",
    "        print(\"Model and tokenizer loaded successfully\")\n",
    "        # Force garbage collection to free memory\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return model, tokenizer\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR loading models: {e}\")\n",
    "        raise\n",
    "\n",
    "def prepare_dataset(df, tokenizer):\n",
    "    \"\"\"Prepare and tokenize the dataset.\"\"\"\n",
    "    print(f\"Preparing dataset with {len(df)} examples\")\n",
    "    \n",
    "    try:\n",
    "        # Convert DataFrame to Dataset\n",
    "        dataset = Dataset.from_pandas(df)\n",
    "        print(f\"Dataset columns: {dataset.column_names}\")\n",
    "        \n",
    "        # Define preprocessing function\n",
    "        def preprocess_function(examples):\n",
    "            inputs = examples[\"Text\"]\n",
    "            targets = examples[\"Summary\"]\n",
    "            \n",
    "            # Tokenize inputs\n",
    "            model_inputs = tokenizer(\n",
    "                inputs, \n",
    "                max_length=MAX_INPUT_LENGTH,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True\n",
    "            )\n",
    "            \n",
    "            # Tokenize targets\n",
    "            with tokenizer.as_target_tokenizer():\n",
    "                labels = tokenizer(\n",
    "                    targets,\n",
    "                    max_length=MAX_OUTPUT_LENGTH,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True\n",
    "                )\n",
    "            \n",
    "            model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "            return model_inputs\n",
    "        \n",
    "        # Process the dataset\n",
    "        print(\"Starting dataset tokenization...\")\n",
    "        tokenized_dataset = dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            remove_columns=dataset.column_names,\n",
    "            desc=\"Tokenizing dataset\"\n",
    "        )\n",
    "        \n",
    "        print(f\"Dataset preparation complete. Feature names: {tokenized_dataset.column_names}\")\n",
    "        print(f\"Dataset size: {len(tokenized_dataset)}\")\n",
    "        return tokenized_dataset\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in dataset preparation: {e}\")\n",
    "        raise\n",
    "\n",
    "def compute_entailment_score(input_ids, attention_mask, summary_ids, summary_attention_mask, model):\n",
    "    \"\"\"Calculate a proxy for entailment score between document and summary.\"\"\"\n",
    "    try:\n",
    "        print(f\"Computing entailment score. Input shape: {input_ids.shape}, Summary shape: {summary_ids.shape}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get document embeddings - access LED encoder directly\n",
    "            doc_outputs = model.base_model.led.encoder(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "            )\n",
    "            doc_embedding = doc_outputs.last_hidden_state.mean(dim=1)\n",
    "            \n",
    "            # Get summary embeddings\n",
    "            summary_outputs = model.base_model.led.encoder(\n",
    "                input_ids=summary_ids,\n",
    "                attention_mask=summary_attention_mask,\n",
    "            )\n",
    "            summary_embedding = summary_outputs.last_hidden_state.mean(dim=1)\n",
    "            \n",
    "            # Normalize embeddings\n",
    "            doc_embedding = doc_embedding / (doc_embedding.norm(dim=1, keepdim=True) + 1e-8)\n",
    "            summary_embedding = summary_embedding / (summary_embedding.norm(dim=1, keepdim=True) + 1e-8)\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            similarity = torch.bmm(\n",
    "                doc_embedding.unsqueeze(1), \n",
    "                summary_embedding.unsqueeze(2)\n",
    "            ).squeeze()\n",
    "            \n",
    "            # Transform to a probability-like score between 0 and 1\n",
    "            entailment_score = (similarity + 1) / 2\n",
    "            \n",
    "            print(f\"Entailment score: {entailment_score.item():.4f}\")\n",
    "            return entailment_score\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in entailment calculation: {e}\")\n",
    "        return torch.tensor([0.5], device=device)  # Fallback value\n",
    "\n",
    "def calculate_rewards(input_ids, attention_mask, generated_ids, generated_attention_mask, model, tokenizer):\n",
    "    \"\"\"Calculate rewards for a batch of generated summaries using only entailment scores.\"\"\"\n",
    "    try:\n",
    "        print(f\"Calculating rewards for batch of size {input_ids.shape[0]}\")\n",
    "        batch_size = input_ids.shape[0]\n",
    "        rewards = torch.zeros(batch_size, device=device)\n",
    "        \n",
    "        # Initialize base reward value - higher than 0 to promote training stability\n",
    "        base_reward = 0.3\n",
    "        \n",
    "        # We'll measure primarily with entailment\n",
    "        for i in range(batch_size):\n",
    "            # Calculate entailment score\n",
    "            entailment_score = compute_entailment_score(\n",
    "                input_ids[i:i+1], \n",
    "                attention_mask[i:i+1],\n",
    "                generated_ids[i:i+1], \n",
    "                generated_attention_mask[i:i+1],\n",
    "                model\n",
    "            )\n",
    "            \n",
    "            # No KL divergence - replaced with simpler approach\n",
    "            # Add length penalty to avoid extremely short summaries\n",
    "            summary_length = (generated_ids[i] != tokenizer.pad_token_id).sum()\n",
    "            length_factor = min(1.0, summary_length / 50)  # Scale up to 1.0 based on minimum desired length\n",
    "            \n",
    "            # Combine rewards - primarily entailment-based with length factor\n",
    "            combined_reward = base_reward + ENTAILMENT_WEIGHT * entailment_score.item() * length_factor\n",
    "            rewards[i] = combined_reward\n",
    "            print(f\"Reward for example {i+1}: {combined_reward:.4f}\")\n",
    "        \n",
    "        print(f\"Average batch reward: {rewards.mean().item():.4f}\")\n",
    "        return rewards\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in reward calculation: {e}\")\n",
    "        # Return default rewards to avoid stopping training\n",
    "        return torch.ones(input_ids.shape[0], device=device) * 0.5\n",
    "\n",
    "def main(train_df):\n",
    "    \"\"\"Main function to run the training pipeline.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STARTING LORA TRAINING PIPELINE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        # Load model and tokenizer with LoRA\n",
    "        model, tokenizer = load_models_and_tokenizer()\n",
    "        \n",
    "        # Prepare dataset\n",
    "        tokenized_dataset = prepare_dataset(train_df, tokenizer)\n",
    "        \n",
    "        # Create data collator\n",
    "        print(\"Creating data collator...\")\n",
    "        data_collator = DataCollatorForSeq2Seq(\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Create DataLoader\n",
    "        print(\"Creating DataLoader...\")\n",
    "        train_dataloader = DataLoader(\n",
    "            tokenized_dataset, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=True, \n",
    "            collate_fn=data_collator\n",
    "        )\n",
    "        print(f\"Created DataLoader with {len(train_dataloader)} batches\")\n",
    "        \n",
    "        # Initialize optimizer - using 8-bit Adam to save memory\n",
    "        print(\"Initializing optimizer...\")\n",
    "        try:\n",
    "            from bitsandbytes.optim import Adam8bit\n",
    "            optimizer = Adam8bit(model.parameters(), lr=LEARNING_RATE)\n",
    "            print(\"Using 8-bit Adam optimizer for memory efficiency\")\n",
    "        except ImportError:\n",
    "            print(\"Bitsandbytes not available, using standard AdamW\")\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "        \n",
    "        # Create scheduler\n",
    "        num_training_steps = len(train_dataloader) * NUM_EPOCHS\n",
    "        num_warmup_steps = int(0.1 * num_training_steps)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=num_warmup_steps, \n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"STARTING TRAINING\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        global_step = 0\n",
    "        total_loss = 0\n",
    "        \n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "            epoch_loss = 0\n",
    "            epoch_rewards = []\n",
    "            \n",
    "            # Create progress bar for the epoch\n",
    "            progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Epoch {epoch+1}\")\n",
    "            \n",
    "            for step, batch in progress_bar:\n",
    "                print(f\"\\nProcessing batch {step+1}/{len(train_dataloader)} in epoch {epoch+1}\")\n",
    "                \n",
    "                # Move batch to device\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                \n",
    "                # Forward pass\n",
    "                print(\"Running forward pass...\")\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "                print(f\"Loss: {loss.item():.4f}\")\n",
    "                \n",
    "                # Generate summaries for reward calculation\n",
    "                print(\"Generating summaries for reward calculation...\")\n",
    "                with torch.no_grad():\n",
    "                    generated_ids = model.generate(\n",
    "                        input_ids=batch[\"input_ids\"],\n",
    "                        attention_mask=batch[\"attention_mask\"],\n",
    "                        max_length=MAX_OUTPUT_LENGTH,\n",
    "                        num_beams=2,  # Reduced from 4 to save memory\n",
    "                        early_stopping=True\n",
    "                    )\n",
    "                \n",
    "                # Create attention mask for generated IDs\n",
    "                generated_attention_mask = torch.ones_like(generated_ids)\n",
    "                \n",
    "                # Calculate rewards\n",
    "                print(\"Calculating rewards...\")\n",
    "                rewards = calculate_rewards(\n",
    "                    batch[\"input_ids\"],\n",
    "                    batch[\"attention_mask\"],\n",
    "                    generated_ids,\n",
    "                    generated_attention_mask,\n",
    "                    model,\n",
    "                    tokenizer\n",
    "                )\n",
    "                \n",
    "                # Calculate reward-weighted loss\n",
    "                print(\"Calculating reward-weighted loss...\")\n",
    "                reward_weighted_loss = loss * rewards.mean()\n",
    "                print(f\"Reward-weighted loss: {reward_weighted_loss.item():.4f}\")\n",
    "                \n",
    "                # Scale loss for gradient accumulation\n",
    "                scaled_loss = reward_weighted_loss / GRADIENT_ACCUMULATION_STEPS\n",
    "                scaled_loss.backward()\n",
    "                \n",
    "                # Update weights (with gradient accumulation)\n",
    "                if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                    print(\"Updating weights...\")\n",
    "                    # Gradient clipping to prevent exploding gradients\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    \n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    global_step += 1\n",
    "                    \n",
    "                    # Log metrics\n",
    "                    avg_reward = rewards.mean().item()\n",
    "                    epoch_rewards.append(avg_reward)\n",
    "                    epoch_loss += loss.item()\n",
    "                    \n",
    "                    progress_bar.set_postfix({\n",
    "                        \"loss\": f\"{loss.item():.4f}\",\n",
    "                        \"reward\": f\"{avg_reward:.4f}\",\n",
    "                        \"lr\": f\"{scheduler.get_last_lr()[0]:.6f}\"\n",
    "                    })\n",
    "                    \n",
    "                    # Save checkpoint periodically\n",
    "                    if global_step % SAVE_STEPS == 0:\n",
    "                        checkpoint_dir = os.path.join(OUTPUT_DIR, f\"checkpoint-{global_step}\")\n",
    "                        print(f\"Saving LoRA checkpoint to {checkpoint_dir}\")\n",
    "                        model.save_pretrained(checkpoint_dir)\n",
    "                        tokenizer.save_pretrained(checkpoint_dir)\n",
    "                        \n",
    "                        # Log example generation\n",
    "                        if len(batch[\"input_ids\"]) > 0:\n",
    "                            input_text = tokenizer.decode(batch[\"input_ids\"][0], skip_special_tokens=True)\n",
    "                            generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "                            \n",
    "                            print(\"\\nExample generation:\")\n",
    "                            print(f\"Input (truncated): {input_text[:200]}...\")\n",
    "                            print(f\"Generated summary: {generated_text}\")\n",
    "                \n",
    "                # Force garbage collection periodically\n",
    "                if step % 10 == 0:\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            # Save model after each epoch\n",
    "            epoch_dir = os.path.join(OUTPUT_DIR, f\"epoch-{epoch+1}\")\n",
    "            print(f\"Saving LoRA model after epoch {epoch+1} to {epoch_dir}\")\n",
    "            model.save_pretrained(epoch_dir)\n",
    "            tokenizer.save_pretrained(epoch_dir)\n",
    "            \n",
    "            # Log epoch metrics\n",
    "            avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
    "            avg_epoch_reward = sum(epoch_rewards) / len(epoch_rewards) if epoch_rewards else 0\n",
    "            print(f\"Epoch {epoch+1} metrics: Loss={avg_epoch_loss:.4f}, Reward={avg_epoch_reward:.4f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TRAINING COMPLETE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Save final model\n",
    "        final_model_dir = os.path.join(OUTPUT_DIR, \"final-model\")\n",
    "        print(f\"Saving final LoRA model to {final_model_dir}\")\n",
    "        model.save_pretrained(final_model_dir)\n",
    "        tokenizer.save_pretrained(final_model_dir)\n",
    "        \n",
    "        return model, tokenizer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"CRITICAL ERROR IN TRAINING: {e}\")\n",
    "        print(\"=\"*50)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Try to save the model if it exists\n",
    "        try:\n",
    "            if 'model' in locals():\n",
    "                emergency_save_dir = os.path.join(OUTPUT_DIR, \"emergency-save\")\n",
    "                print(f\"Attempting emergency save to {emergency_save_dir}\")\n",
    "                model.save_pretrained(emergency_save_dir)\n",
    "                if 'tokenizer' in locals():\n",
    "                    tokenizer.save_pretrained(emergency_save_dir)\n",
    "                print(\"Emergency save successful\")\n",
    "        except Exception as save_error:\n",
    "            print(f\"Emergency save failed: {save_error}\")\n",
    "        \n",
    "        raise\n",
    "\n",
    "def load_and_merge_lora_model(base_model_path, lora_model_path):\n",
    "    \"\"\"Load a LoRA model and merge it with the base model for inference.\"\"\"\n",
    "    print(f\"Loading and merging LoRA model from {lora_model_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Load the base model\n",
    "        base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            base_model_path,\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "        base_model = base_model.to(device)  # Move to GPU manually\n",
    "        \n",
    "        # Load the LoRA configuration\n",
    "        peft_config = PeftConfig.from_pretrained(lora_model_path)\n",
    "        \n",
    "        # Load the LoRA model\n",
    "        model = PeftModel.from_pretrained(base_model, lora_model_path)\n",
    "        \n",
    "        # Merge the models (optional, for deployment efficiency)\n",
    "        # model = model.merge_and_unload()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR loading and merging model: {e}\")\n",
    "        raise\n",
    "\n",
    "def test_model(model, tokenizer, test_df, num_examples=3):\n",
    "    \"\"\"Test the model on sample documents.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"TESTING MODEL ON {num_examples} EXAMPLES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    try:\n",
    "        for i in range(min(num_examples, len(test_df))):\n",
    "            # Get a sample document\n",
    "            sample_doc = test_df.iloc[i][\"Text\"]\n",
    "            original_summary = test_df.iloc[i][\"Summary\"]\n",
    "            \n",
    "            print(f\"\\nProcessing test example {i+1}/{num_examples}\")\n",
    "            \n",
    "            # Tokenize\n",
    "            print(\"Tokenizing input...\")\n",
    "            inputs = tokenizer(\n",
    "                sample_doc,\n",
    "                max_length=MAX_INPUT_LENGTH,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "            \n",
    "            # Generate summary\n",
    "            print(\"Generating summary...\")\n",
    "            with torch.no_grad():\n",
    "                generated_ids = model.generate(\n",
    "                    input_ids=inputs[\"input_ids\"],\n",
    "                    attention_mask=inputs[\"attention_mask\"],\n",
    "                    max_length=MAX_OUTPUT_LENGTH,\n",
    "                    num_beams=4,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "            \n",
    "            # Decode\n",
    "            generated_summary = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "            \n",
    "            print(f\"\\nExample {i+1}:\")\n",
    "            print(f\"Original document (truncated): {sample_doc[:200]}...\")\n",
    "            print(f\"Original summary: {original_summary}\")\n",
    "            print(f\"Generated summary: {generated_summary}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during testing: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Example usage of the code\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STARTING SCRIPT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        # Verify train_df exists and has the right structure\n",
    "        print(\"Checking training data...\")\n",
    "        print(f\"train_df type: {type(train_df)}\")\n",
    "        print(f\"train_df shape: {train_df.shape}\")\n",
    "        print(f\"train_df columns: {train_df.columns.tolist()}\")\n",
    "        \n",
    "        if \"Text\" not in train_df.columns or \"Summary\" not in train_df.columns:\n",
    "            print(\"ERROR: train_df missing required columns 'Text' and 'Summary'\")\n",
    "            raise ValueError(\"Dataset missing required columns\")\n",
    "            \n",
    "        # Train the model\n",
    "        model, tokenizer = main(train_df)\n",
    "        \n",
    "        # Test the model\n",
    "        test_model(model, tokenizer, train_df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"SCRIPT FAILED: {e}\")\n",
    "        print(\"=\"*50)\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e989208",
   "metadata": {
    "papermill": {
     "duration": 0.051357,
     "end_time": "2025-05-12T18:38:55.855426",
     "exception": false,
     "start_time": "2025-05-12T18:38:55.804069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6605181,
     "sourceId": 10665272,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6655535,
     "sourceId": 10734245,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7328493,
     "sourceId": 11676566,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39847.988301,
   "end_time": "2025-05-12T18:38:58.903321",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-12T07:34:50.915020",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b35f97291f94bebbaef1894e0dfba5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0bce46d110d349d7aff04317048f9fdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0c3c84b73ef74f7bb36999690516cc4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b2d4d972841144ac92dd25f79f38b4ca",
        "IPY_MODEL_927c4299590a4fcf9505b028dc3c3389",
        "IPY_MODEL_4e9511520fa64f0da3b2571eca5f1fa2"
       ],
       "layout": "IPY_MODEL_ad77bd8237d6448bbb94e7ccf0d97561",
       "tabbable": null,
       "tooltip": null
      }
     },
     "11727552e7ca4d4396050c51b470e388": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5df3d84785644d8b99cecff730d11590",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_effe034986e548f99ce0ce6721b46744",
       "tabbable": null,
       "tooltip": null,
       "value": "Epochâ€‡1:â€‡100%"
      }
     },
     "12f09c7f2d004cca9f1a21d5d7c4f160": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "194a1aa8ed8a44de85c3b58a2964937b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_11727552e7ca4d4396050c51b470e388",
        "IPY_MODEL_3e5780f9f1b441f6bde7d15cbab96998",
        "IPY_MODEL_eafe8b3275844299966c53c2db6f61cf"
       ],
       "layout": "IPY_MODEL_4ac968e875514cb09b845ae448872ec6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "19efce8a255f4f43817712070c77d925": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a8671b813514e59bcd0068bb2064500": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ca8d33a757546d8ae666d5f8630fd77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0b35f97291f94bebbaef1894e0dfba5d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_8f02250227784d3fb45fd3b13b89b9e5",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:â€‡100%"
      }
     },
     "1cddc096c265424492b44c522114474d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_869b43a1756c4aba9768197fa804a356",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_43a96200aaa745b3ab601362b825a76b",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:â€‡100%"
      }
     },
     "1e6a192409b443db93c5133e60bb2ea0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f97e143c535b4408bc4ee13ef624aead",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_5627643f6aa341ec98a51c680b610c0d",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡772/772â€‡[00:00&lt;00:00,â€‡80.1kB/s]"
      }
     },
     "2061631d70514496806e2b3dfa42bbda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28c8de27813844cfbb5f2cb7c59aeb59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_84fb8e14836f4c3283f2f7d31be7d1a2",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_12f09c7f2d004cca9f1a21d5d7c4f160",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json:â€‡100%"
      }
     },
     "29ba5ff6d125424790f97890fbca2023": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_76debc0a77e74e6889ec19a0b216aebb",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_eac69fd2e17640a3a3a456aaaf9496d3",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡798k/798kâ€‡[00:00&lt;00:00,â€‡13.8MB/s]"
      }
     },
     "30820e966fb7427a93f348a00c853bb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3fa4d689fa8a4d8b98d4cb0cf3738248",
        "IPY_MODEL_c63f821cedae4cdba36d16769e144488",
        "IPY_MODEL_b693d807b2244db48168b30391e6acf8"
       ],
       "layout": "IPY_MODEL_ea937ca6bf654be2912d185153025b0a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3e5780f9f1b441f6bde7d15cbab96998": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_19efce8a255f4f43817712070c77d925",
       "max": 200.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a2e168b1b56b4f309bcf9f278f8e63b5",
       "tabbable": null,
       "tooltip": null,
       "value": 200.0
      }
     },
     "3fa4d689fa8a4d8b98d4cb0cf3738248": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ead7af6140194df693dd69ea7b525b92",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_70871bf6bcfc479b9bf16c5946163efe",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt:â€‡100%"
      }
     },
     "41fc1350a9b543d1811cb1caf619d258": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "43a96200aaa745b3ab601362b825a76b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "49517428ed254f43ae70e9003c570c43": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ac968e875514cb09b845ae448872ec6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4b60aa4318704ddb981a52a8a493d65a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_70cc225d987f4c8eb7b87786a040f162",
       "max": 798293.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_afab6e6468e34e23813163c6c594e338",
       "tabbable": null,
       "tooltip": null,
       "value": 798293.0
      }
     },
     "4e7fb924f76b400282cb5ae1bea29b8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a5226f2919944c39b64b898344d8239a",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_670d42d8f6b449c789d8741e72cb5988",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1.15k/1.15kâ€‡[00:00&lt;00:00,â€‡133kB/s]"
      }
     },
     "4e9511520fa64f0da3b2571eca5f1fa2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d367da6b64e843cc84e6fdd126dfb03c",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_41fc1350a9b543d1811cb1caf619d258",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡400/400â€‡[00:03&lt;00:00,â€‡106.06â€‡examples/s]"
      }
     },
     "4f41616bbb9a48cd9caad9c426c88f2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5627643f6aa341ec98a51c680b610c0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "586664426d9c47d99fe27735511319eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d1b69f6b87d4ec89c6ef90997c378dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9c63f308e8c6433682d05b979417a367",
       "max": 1152.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aa12d31e90cf4a11ad67ed1197d31358",
       "tabbable": null,
       "tooltip": null,
       "value": 1152.0
      }
     },
     "5d21b7eab99d47029e0ae6020e666778": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5dab5ab32b504260848b3d593ea79492": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5df3d84785644d8b99cecff730d11590": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6572f636afd5462c9e416029dca4984a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "670d42d8f6b449c789d8741e72cb5988": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "70871bf6bcfc479b9bf16c5946163efe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "70cc225d987f4c8eb7b87786a040f162": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73872399809f4a3ca4512d42b2f1f1a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7595bd08d233477bb895faf0df0edb7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76debc0a77e74e6889ec19a0b216aebb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82da3bffa2e348efa7fd7921837806c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8abb24a3fec9440da8f82bbc581e9598",
       "max": 1057.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_84e45722148643bda73c873e78e1901a",
       "tabbable": null,
       "tooltip": null,
       "value": 1057.0
      }
     },
     "84e45722148643bda73c873e78e1901a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "84fb8e14836f4c3283f2f7d31be7d1a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "858f4ba456a84bc28557f3a0a978e2a8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "869b43a1756c4aba9768197fa804a356": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "896551e5666247eeb0398663235f6dad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ca8d33a757546d8ae666d5f8630fd77",
        "IPY_MODEL_5d1b69f6b87d4ec89c6ef90997c378dd",
        "IPY_MODEL_4e7fb924f76b400282cb5ae1bea29b8c"
       ],
       "layout": "IPY_MODEL_7595bd08d233477bb895faf0df0edb7e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8abb24a3fec9440da8f82bbc581e9598": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f02250227784d3fb45fd3b13b89b9e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "927c4299590a4fcf9505b028dc3c3389": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_586664426d9c47d99fe27735511319eb",
       "max": 400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4f41616bbb9a48cd9caad9c426c88f2c",
       "tabbable": null,
       "tooltip": null,
       "value": 400.0
      }
     },
     "9c63f308e8c6433682d05b979417a367": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f08f8e9239345ee8a55ea40d9e7ed1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a2e168b1b56b4f309bcf9f278f8e63b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a407ef211034435fab65acfcee41ef93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a5226f2919944c39b64b898344d8239a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a5bedf344aec48ce8df151e6eded22c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa12d31e90cf4a11ad67ed1197d31358": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ad77bd8237d6448bbb94e7ccf0d97561": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afab6e6468e34e23813163c6c594e338": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b2d4d972841144ac92dd25f79f38b4ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fb4a59f3d97b4f05bc1afa2701497882",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_ccc7ab30f7534a18836e35585d672038",
       "tabbable": null,
       "tooltip": null,
       "value": "Tokenizingâ€‡dataset:â€‡100%"
      }
     },
     "b693d807b2244db48168b30391e6acf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1a8671b813514e59bcd0068bb2064500",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0bce46d110d349d7aff04317048f9fdf",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡14.9MB/s]"
      }
     },
     "bd94bdae157d409886a3762e6950061a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e73ea66d73734bfdab8dfdd00518ec03",
        "IPY_MODEL_82da3bffa2e348efa7fd7921837806c0",
        "IPY_MODEL_d358eb0d004f469fb916549f96d2a5a2"
       ],
       "layout": "IPY_MODEL_d33bdcfbdd9d49df828f8e6c07296717",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bdbe7c707bcc43f7aefe92ef8c1a0372": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_28c8de27813844cfbb5f2cb7c59aeb59",
        "IPY_MODEL_4b60aa4318704ddb981a52a8a493d65a",
        "IPY_MODEL_29ba5ff6d125424790f97890fbca2023"
       ],
       "layout": "IPY_MODEL_5d21b7eab99d47029e0ae6020e666778",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c63f821cedae4cdba36d16769e144488": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a5bedf344aec48ce8df151e6eded22c5",
       "max": 456356.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5dab5ab32b504260848b3d593ea79492",
       "tabbable": null,
       "tooltip": null,
       "value": 456356.0
      }
     },
     "cc77394675c547bd96b6539937956309": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_858f4ba456a84bc28557f3a0a978e2a8",
       "max": 772.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_73872399809f4a3ca4512d42b2f1f1a0",
       "tabbable": null,
       "tooltip": null,
       "value": 772.0
      }
     },
     "ccc7ab30f7534a18836e35585d672038": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d33bdcfbdd9d49df828f8e6c07296717": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d358eb0d004f469fb916549f96d2a5a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2061631d70514496806e2b3dfa42bbda",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_e63256cd1f734fd3be7d72fdcf5dd81c",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1.06k/1.06kâ€‡[00:00&lt;00:00,â€‡110kB/s]"
      }
     },
     "d367da6b64e843cc84e6fdd126dfb03c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6217c772dda4780b5014084cb4efa29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e63256cd1f734fd3be7d72fdcf5dd81c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e73ea66d73734bfdab8dfdd00518ec03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_49517428ed254f43ae70e9003c570c43",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_9f08f8e9239345ee8a55ea40d9e7ed1a",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:â€‡100%"
      }
     },
     "e80e4cd9223d400cbf53f9124c12f7f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1cddc096c265424492b44c522114474d",
        "IPY_MODEL_cc77394675c547bd96b6539937956309",
        "IPY_MODEL_1e6a192409b443db93c5133e60bb2ea0"
       ],
       "layout": "IPY_MODEL_e6217c772dda4780b5014084cb4efa29",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ea937ca6bf654be2912d185153025b0a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eac69fd2e17640a3a3a456aaaf9496d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ead7af6140194df693dd69ea7b525b92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eafe8b3275844299966c53c2db6f61cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a407ef211034435fab65acfcee41ef93",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_6572f636afd5462c9e416029dca4984a",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡200/200â€‡[10:54:42&lt;00:00,â€‡196.67s/it,â€‡loss=3.6914,â€‡reward=0.8640,â€‡lr=0.000111]"
      }
     },
     "effe034986e548f99ce0ce6721b46744": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f97e143c535b4408bc4ee13ef624aead": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb4a59f3d97b4f05bc1afa2701497882": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
